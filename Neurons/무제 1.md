---
title: image-classification-underfitting-data
created: 2025-08-16
modified: 2025-08-16

tags:

- problem/classification
    
- method/transfer-learning
    
- technique/data-augmentation
    
- constraint/small-dataset
    
- metric/accuracy
    
    aliases: ["underfitting", "low-accuracy", "transfer-learning-low-data"]
    
---


# 이미지 분류 모델의 과소적합 해결 - 전이 학습과 데이터 증강

## 🎯 핵심 포인트

모델의 정확도가 훈련 및 검증 데이터에서 모두 낮아 **과소적합(Underfitting)**이 발생한 경우, **훈련 데이터의 양을 늘려 모델의 편향(Bias)을 줄여** 정확도를 향상시킬 수 있습니다.

---

## 📝 설명

### 전이 학습(Transfer Learning)이 소규모 데이터셋에 적합한 이유

전이 학습은 대규모 데이터셋으로 사전 훈련된 모델의 가중치를 가져와 새로운 작업에 미세 조정하는 기술입니다. 이 방식은 모델이 이미 일반적인 시각적 특징(선, 모서리, 질감 등)을 학습했기 때문에, 새로운 데이터를 처음부터 학습하는 것보다 훨씬 적은 데이터로도 높은 성능을 달성할 수 있습니다. 특히, 훈련 데이터가 부족한 **소규모 데이터셋** 문제에 매우 효과적입니다.

그러나 본 사례에서는 300개의 이미지만으로는 전이 학습 모델조차도 충분히 새로운 특징을 학습하지 못해, 훈련 및 검증 정확도가 모두 낮게 나타나는 **과소적합** 문제가 발생했습니다.

### 아키텍처 플로우

```
사전 훈련된 모델 (파트너 회사)
      ↓
새로운 훈련 데이터 (300개 이미지)
      ↓
전이 학습 (최상단 레이어 재훈련)
      ↓
       73% 정확도 (과소적합)
       ↓
       새로운 이미지 추가 / 데이터 증강
       ↓
훈련 데이터셋 확장
       ↓
모델 재훈련
       ↓
       정확도 향상 (95% 이상 목표)
```

### Trade-offs 고려사항

**훈련 데이터 증강 장점**:

- **모델의 일반화 능력 향상**: 다양한 변형을 학습하여 실제 환경의 새로운 데이터에 대한 성능이 높아집니다.
    
- **과소적합 해결**: 데이터 부족으로 인한 모델의 편향을 줄여 훈련 및 검증 정확도를 동시에 높입니다.
    
- **추가 비용 감소**: 새로운 이미지를 수집하는 것보다 비용 효율적입니다.
    

**훈련 데이터 증강 단점**:

- **잠재적 오버피팅**: 너무 공격적인 증강은 모델이 증강된 데이터의 인공적인 특성을 학습하여 과대적합을 유발할 수 있습니다.
    
- **계산 비용 증가**: 데이터셋이 커지므로 훈련 시간이 늘어날 수 있습니다.
    
- **제한된 다양성**: 원본 데이터의 다양성 한계를 완전히 극복할 수는 없습니다.
    

**대안: 모델 복잡도 증가(레이어 추가) 장점**:

- **모델 표현력 향상**: 더 많은 레이어를 통해 복잡한 패턴을 학습할 수 있습니다.
    

**대안: 모델 복잡도 증가(레이어 추가) 단점**:

- **과대적합 유발**: 데이터가 300장밖에 없는 상황에서 레이어를 늘리면 모델이 불필요한 노이즈까지 학습하여 과대적합이 발생할 가능성이 매우 높습니다. 이로 인해 훈련 정확도는 높아지지만, 검증 정확도는 낮아질 수 있습니다.
    

---

## 🔍 주요개념

### 과소적합(Underfitting) vs. 과대적합(Overfitting)

- **과소적합(Underfitting)**: 모델이 훈련 데이터를 충분히 학습하지 못해 **편향(Bias)이 높은** 상태. 훈련 데이터와 검증 데이터 모두에서 성능이 낮게 나타납니다. 이는 데이터 부족, 단순한 모델, 또는 불충분한 훈련 횟수 때문에 발생할 수 있습니다.
    
- **과대적합(Overfitting)**: 모델이 훈련 데이터의 노이즈까지 학습하여 **분산(Variance)이 높은** 상태. 훈련 데이터에서는 매우 높은 성능을 보이지만, 새로운 검증 데이터에서는 성능이 현저히 떨어집니다. 이는 복잡한 모델, 과도한 훈련, 또는 데이터 부족 때문에 발생할 수 있습니다.
    

### 실전 적용

- **데이터 증강**: `ImageDataGenerator`와 같은 도구를 사용하여 이미지를 무작위로 회전, 확대/축소, 좌우 반전, 밝기 조절 등을 적용하여 훈련 데이터의 양을 늘릴 수 있습니다.
    
- **추가 데이터 수집**: 실제 공정 라인에서 불량/정상 서킷보드 이미지를 추가로 확보하여 데이터셋을 확장합니다.
    
- **전이 학습의 재활용**: 확장된 데이터셋을 사용하여 사전 훈련된 모델을 다시 미세 조정합니다. 이 과정에서 동결된(frozen) 레이어의 수를 조절하며 최적의 성능을 찾아야 합니다.
    

---

## 📝 관련 문제

**Question:** An electronics manufacturing company is building an image classification model to detect whether a circuit board is defective or not. To decrease training time, a Machine Learning Specialist implemented transfer learning using 300 images on a pre-trained neural network obtained from a partner company. The company requires a model accuracy of no less than 95% to be feasible. The Specialist conducted a full grid search through a wide hyperparameter space. However, the optimal values returned only 73% and 72% accuracy on the training and validation set, respectively. How can the Specialist increase the model accuracy?

**Options:**

- A) Regularize the model by randomly dropping nodes.
    
- B) Increase the variance using a pre-trained neural network with more layers for transfer learning.
    
- C) Collect additional images and add them to the training data to decrease the bias, then retrain the model using transfer learning.
    
- D) Use Amazon SageMaker’s automatic model tuning to find the best hyperparameter values for the model.
    

**정답: C) Collect additional images and add them to the training data to decrease the bias, then retrain the model using transfer learning.**

💡 추가 설명:

- **오답 옵션 A**: 드롭아웃(Regularization)은 과대적합을 방지하는 기술입니다. 현재 모델은 과소적합 상태이므로, 드롭아웃을 적용하면 오히려 성능이 더 저하될 수 있습니다.
    
- **오답 옵션 B**: 더 많은 레이어는 모델의 복잡도를 높여 과대적합을 유발할 수 있습니다. 300개의 데이터만으로는 복잡한 모델을 학습하기에 부족합니다.
    
- **오답 옵션 D**: 이미 넓은 범위의 하이퍼파라미터 탐색(Grid Search)을 수행했으므로, 하이퍼파라미터의 문제라기보다는 데이터의 양이 부족하여 발생한 과소적합 문제입니다. 자동 모델 튜닝으로 정확도가 크게 향상될 가능성은 낮습니다.