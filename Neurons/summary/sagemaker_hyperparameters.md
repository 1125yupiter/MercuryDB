# π€ AWS SageMaker λΉνΈμΈ μ•κ³ λ¦¬μ¦ ν•μ΄νΌνλΌλ―Έν„° μ™„λ²½ κ°€μ΄λ“

μ•λ…•ν•μ„Έμ”! μ¤λμ€ AWS SageMakerμ λΉνΈμΈ μ•κ³ λ¦¬μ¦λ“¤μ ν•μ΄νΌνλΌλ―Έν„°μ— λ€ν•΄ μμ„Έν μ•μ•„λ³΄κ² μµλ‹λ‹¤. 

λ¨Έμ‹ λ¬λ‹ λ¨λΈμ„ ν›λ ¨ν•  λ• κ°€μ¥ μ¤‘μ”ν• κ²ƒ μ¤‘ ν•λ‚κ°€ λ°”λ΅ **ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •**μΈλ°μ”, μ–΄λ–¤ νλΌλ―Έν„°κ°€ ν•„μμ΄κ³  μ–΄λ–¤ κ²ƒμ΄ μ„ νƒμ‚¬ν•­μΈμ§€ μ •ν™•ν μ•„λ” κ²ƒμ΄ μ¤‘μ”ν•©λ‹λ‹¤! π“

## π“‹ ν•μ΄νΌνλΌλ―Έν„°λ€?

ν•μ΄νΌνλΌλ―Έν„°λ” λ¨λΈ ν›λ ¨ μ „μ— μ‚¬μ©μκ°€ μ§μ ‘ μ„¤μ •ν•΄μ•Ό ν•λ” κ°’λ“¤μ…λ‹λ‹¤. ν¬κ² λ‘ μΆ…λ¥λ΅ λ‚λ‰©λ‹λ‹¤:

- **ν•„μ ν•μ΄νΌνλΌλ―Έν„°** π”΄: λ°λ“μ‹ μ„¤μ •ν•΄μ•Ό ν•λ” νλΌλ―Έν„° (μ„¤μ •ν•μ§€ μ•μΌλ©΄ ν›λ ¨ μ‹¤ν¨)
- **μ„ νƒ ν•μ΄νΌνλΌλ―Έν„°** π΅: κΈ°λ³Έκ°’μ΄ μμ–΄μ„ μƒλµ κ°€λ¥ν• νλΌλ―Έν„°

---

## 1οΈβƒ£ XGBoost μ•κ³ λ¦¬μ¦

### π”΄ ν•„μ ν•μ΄νΌνλΌλ―Έν„°
- **`num_round`**: λ¶€μ¤ν… λΌμ΄λ“ μ (ν›λ ¨ λ°λ³µ νμ) - **ν•­μƒ ν•„μ**
- **`num_class`**: ν΄λμ¤ μ - **λ‹¤μ¤‘ ν΄λμ¤ λ¶„λ¥**(`multi:softmax` λλ” `multi:softprob`) μ‹μ—λ§ ν•„μ

### π΅ μ£Όμ” μ„ νƒ ν•μ΄νΌνλΌλ―Έν„°
- `max_depth`: νΈλ¦¬μ μµλ€ κΉμ΄ (κΈ°λ³Έκ°’: 6)
- `eta`: ν•™μµλ¥  (κΈ°λ³Έκ°’: 0.3)
- `gamma`: λ¦¬ν”„ λ…Έλ“ λ¶„ν• μ„ μ„ν• μµμ† μ†μ‹¤ κ°μ† (κΈ°λ³Έκ°’: 0)
- `min_child_weight`: μμ‹ λ…Έλ“μ— ν•„μ”ν• μµμ† κ°€μ¤‘μΉ ν•© (κΈ°λ³Έκ°’: 1)
- `subsample`: ν›λ ¨ μƒν” μ„λΈμƒν”λ§ λΉ„μ¨ (κΈ°λ³Έκ°’: 1)
- `colsample_bytree`: νΈλ¦¬ κµ¬μ„± μ‹ μ—΄ μ„λΈμƒν”λ§ λΉ„μ¨ (κΈ°λ³Έκ°’: 1)
- `objective`: λ©μ ν•¨μ (κΈ°λ³Έκ°’: reg:squarederror)
- `alpha`: L1 μ •κ·ν™” ν•­ (κΈ°λ³Έκ°’: 0)
- `lambda`: L2 μ •κ·ν™” ν•­ (κΈ°λ³Έκ°’: 1)

**π’΅ ν**: XGBoostμ—μ„ `num_round`λ” multi:softprobλΏλ§ μ•„λ‹λΌ **λ¨λ“  μƒν™©μ—μ„ ν•„μ**μ…λ‹λ‹¤!

---

## 2οΈβƒ£ Linear Learner μ•κ³ λ¦¬μ¦

### π”΄ ν•„μ ν•μ΄νΌνλΌλ―Έν„°
- **`predictor_type`**: μμΈ΅κΈ° νƒ€μ… (`binary_classifier`, `multiclass_classifier`, `regressor`)
- **`num_classes`**: ν΄λμ¤ μ - **λ‹¤μ¤‘ ν΄λμ¤ λ¶„λ¥**(`multiclass_classifier`) μ‹μ—λ§ ν•„μ (3~1,000,000)

### π΅ μ£Όμ” μ„ νƒ ν•μ΄νΌνλΌλ―Έν„°
- `epochs`: μµλ€ ν›λ ¨ μ—ν¬ν¬ μ (κΈ°λ³Έκ°’: 15)
- `learning_rate`: ν•™μµλ¥  (κΈ°λ³Έκ°’: auto)
- `mini_batch_size`: λ―Έλ‹ λ°°μΉ ν¬κΈ° (κΈ°λ³Έκ°’: 1000)
- `optimizer`: μµμ ν™” μ•κ³ λ¦¬μ¦ (κΈ°λ³Έκ°’: auto)
- `loss`: μ†μ‹¤ ν•¨μ (κΈ°λ³Έκ°’: auto)
- `l1`: L1 μ •κ·ν™” νλΌλ―Έν„° (κΈ°λ³Έκ°’: auto)
- `wd`: L2 μ •κ·ν™” νλΌλ―Έν„° (κΈ°λ³Έκ°’: auto)
- `use_bias`: νΈν–¥ ν•­ μ‚¬μ© μ—¬λ¶€ (κΈ°λ³Έκ°’: True)
- `normalize_data`: ν”Όμ² μ •κ·ν™” μ—¬λ¶€ (κΈ°λ³Έκ°’: True)

---

## 3οΈβƒ£ Factorization Machines μ•κ³ λ¦¬μ¦

### π”΄ ν•„μ ν•μ΄νΌνλΌλ―Έν„°
- **`feature_dim`**: μ…λ ¥ ν”Όμ² μ°¨μ›μ
- **`num_factors`**: μΈμλ¶„ν•΄ μ°¨μ›μ
- **`predictor_type`**: μμΈ΅κΈ° νƒ€μ… (`binary_classifier`, `regressor`)

### π΅ μ£Όμ” μ„ νƒ ν•μ΄νΌνλΌλ―Έν„°
- `epochs`: ν›λ ¨ μ—ν¬ν¬ μ (κΈ°λ³Έκ°’: 1)
- `bias_lr`: νΈν–¥ ν•™μµλ¥  (κΈ°λ³Έκ°’: 0.1)
- `linear_lr`: μ„ ν• ν•­ ν•™μµλ¥  (κΈ°λ³Έκ°’: 0.01)
- `factors_lr`: μΈμ ν•™μµλ¥  (κΈ°λ³Έκ°’: 0.0001)
- `clip_gradient`: κ·Έλλ””μ–ΈνΈ ν΄λ¦¬ν•‘ μ„κ³„κ°’ (κΈ°λ³Έκ°’: -1.0, λ¬΄μ ν•)

---

## 4οΈβƒ£ K-Means ν΄λ¬μ¤ν„°λ§

### π”΄ ν•„μ ν•μ΄νΌνλΌλ―Έν„°
- **`feature_dim`**: μ…λ ¥ ν”Όμ² μ°¨μ›μ
- **`k`**: ν΄λ¬μ¤ν„° μ

### π΅ μ£Όμ” μ„ νƒ ν•μ΄νΌνλΌλ―Έν„°
- `epochs`: ν›λ ¨ λ°μ΄ν„°λ¥Ό κ±°μΉλ” νμ (κΈ°λ³Έκ°’: 1)
- `init_method`: μ΄κΈ° ν΄λ¬μ¤ν„° μ¤‘μ‹¬μ  μ„ νƒ λ°©λ²• (κΈ°λ³Έκ°’: random)
- `mini_batch_size`: λ―Έλ‹ λ°°μΉ ν¬κΈ° (κΈ°λ³Έκ°’: 5000)
- `extra_center_factor`: μ¶”κ°€ μ¤‘μ‹¬μ  κ³„μ (κΈ°λ³Έκ°’: auto)
- `local_lloyd_max_iter`: Lloyd EM μµλ€ λ°λ³µ νμ (κΈ°λ³Έκ°’: 300)

---

## 5οΈβƒ£ PCA (μ£Όμ„±λ¶„ λ¶„μ„)

### π”΄ ν•„μ ν•μ΄νΌνλΌλ―Έν„°
- **`feature_dim`**: μ…λ ¥ ν”Όμ² μ°¨μ›μ
- **`num_components`**: μ£Όμ„±λ¶„ κ°μ

### π΅ μ„ νƒ ν•μ΄νΌνλΌλ―Έν„°
- `algorithm_mode`: μ•κ³ λ¦¬μ¦ λ¨λ“ (κΈ°λ³Έκ°’: regular)
- `subtract_mean`: ν‰κ·  μ°¨κ° μ—¬λ¶€ (κΈ°λ³Έκ°’: True)
- `extra_components`: μ¶”κ°€ κµ¬μ„±μ”μ† μ (κΈ°λ³Έκ°’: -1, auto)

---

## 6οΈβƒ£ Random Cut Forest (μ΄μƒ νƒμ§€)

### π”΄ ν•„μ ν•μ΄νΌνλΌλ―Έν„°
- **`feature_dim`**: μ…λ ¥ ν”Όμ² μ°¨μ›μ

### π΅ μ„ νƒ ν•μ΄νΌνλΌλ―Έν„°
- `num_samples_per_tree`: νΈλ¦¬λ‹Ή μƒν” μ (κΈ°λ³Έκ°’: 256)
- `num_trees`: ν¬λ μ¤νΈ λ‚΄ νΈλ¦¬ μ (κΈ°λ³Έκ°’: 100)
- `eval_metrics`: ν‰κ°€ λ©”νΈλ¦­ (κΈ°λ³Έκ°’: ["accuracy", "precision_recall_fscore"])

---

## 7οΈβƒ£ Neural Topic Model (NTM)

### π”΄ ν•„μ ν•μ΄νΌνλΌλ―Έν„°
- **`feature_dim`**: μ–΄ν ν¬κΈ°
- **`num_topics`**: ν† ν”½ μ

### π΅ μ£Όμ” μ„ νƒ ν•μ΄νΌνλΌλ―Έν„°
- `epochs`: ν›λ ¨ μ—ν¬ν¬ μ (κΈ°λ³Έκ°’: 50)
- `num_patience_epochs`: μ΅°κΈ° μΆ…λ£ patience (κΈ°λ³Έκ°’: 3)
- `tolerance`: μλ ΄ ν—μ© μ¤μ°¨ (κΈ°λ³Έκ°’: 0.001)
- `optimizer`: μµμ ν™”κΈ° (κΈ°λ³Έκ°’: adadelta)
- `learning_rate`: ν•™μµλ¥  (κΈ°λ³Έκ°’: 0.001)

---

## 8οΈβƒ£ LDA (ν† ν”½ λ¨λΈλ§)

### π”΄ ν•„μ ν•μ΄νΌνλΌλ―Έν„°
- **`feature_dim`**: μ–΄ν ν¬κΈ°
- **`num_topics`**: ν† ν”½ μ

### π΅ μ„ νƒ ν•μ΄νΌνλΌλ―Έν„°
- `alpha0`: ν† ν”½-λ¬Έμ„ λ¶„ν¬μ Dirichlet prior (κΈ°λ³Έκ°’: 1.0)
- `max_restarts`: μµλ€ μ¬μ‹μ‘ νμ (κΈ°λ³Έκ°’: 9)
- `max_iterations`: μµλ€ λ°λ³µ νμ (κΈ°λ³Έκ°’: 1000)
- `tol`: μλ ΄ ν—μ© μ¤μ°¨ (κΈ°λ³Έκ°’: 1e-8)

---

## 9οΈβƒ£ Seq2Seq (μ‹ν€€μ¤-ν¬-μ‹ν€€μ¤)

### π”΄ ν•„μ ν•μ΄νΌνλΌλ―Έν„°
- **`vocab_size`**: μ–΄ν ν¬κΈ°
- **`num_layers_encoder`**: μΈμ½”λ” λ μ΄μ–΄ μ
- **`num_layers_decoder`**: λ””μ½”λ” λ μ΄μ–΄ μ

### π΅ μ£Όμ” μ„ νƒ ν•μ΄νΌνλΌλ―Έν„°
- `rnn_type`: RNN νƒ€μ… (κΈ°λ³Έκ°’: gru)
- `hidden_size`: μ€λ‹‰ μƒνƒ ν¬κΈ° (κΈ°λ³Έκ°’: 512)
- `epochs`: ν›λ ¨ μ—ν¬ν¬ μ (κΈ°λ³Έκ°’: 10)
- `learning_rate`: ν•™μµλ¥  (κΈ°λ³Έκ°’: 0.0003)
- `dropout`: λ“λ΅­μ•„μ›ƒ λΉ„μ¨ (κΈ°λ³Έκ°’: 0.0)

---

## π” DeepAR μ‹κ³„μ—΄ μμΈ΅

### π”΄ ν•„μ ν•μ΄νΌνλΌλ―Έν„°
- **`context_length`**: μ»¨ν…μ¤νΈ κΈΈμ΄
- **`prediction_length`**: μμΈ΅ κΈΈμ΄

### π΅ μ£Όμ” μ„ νƒ ν•μ΄νΌνλΌλ―Έν„°
- `epochs`: ν›λ ¨ μ—ν¬ν¬ μ (κΈ°λ³Έκ°’: 100)
- `num_cells`: LSTM μ…€ μ (κΈ°λ³Έκ°’: 40)
- `num_layers`: LSTM λ μ΄μ–΄ μ (κΈ°λ³Έκ°’: 2)
- `likelihood`: κ°€λ¥λ„ ν•¨μ (κΈ°λ³Έκ°’: student-T)
- `dropout_rate`: λ“λ΅­μ•„μ›ƒ λΉ„μ¨ (κΈ°λ³Έκ°’: 0.1)
- `learning_rate`: ν•™μµλ¥  (κΈ°λ³Έκ°’: 1e-3)

---

## 1οΈβƒ£1οΈβƒ£ BlazingText (ν…μ¤νΈ λ¶„μ„)

### π”΄ ν•„μ ν•μ΄νΌνλΌλ―Έν„°
- **`mode`**: λ¨λ“ (`Word2Vec`, `classification`, `supervised`)

### π΅ Word2Vec λ¨λ“ μ£Όμ” νλΌλ―Έν„°
- `epochs`: ν›λ ¨ μ—ν¬ν¬ μ (κΈ°λ³Έκ°’: 5)
- `learning_rate`: ν•™μµλ¥  (κΈ°λ³Έκ°’: 0.05)
- `vector_dim`: λ²΅ν„° μ°¨μ› (κΈ°λ³Έκ°’: 100)
- `window_size`: μλ„μ° ν¬κΈ° (κΈ°λ³Έκ°’: 5)
- `min_count`: μµμ† λ‹¨μ–΄ μ¶ν„ λΉλ„ (κΈ°λ³Έκ°’: 5)

### π΅ ν…μ¤νΈ λ¶„λ¥ λ¨λ“ μ£Όμ” νλΌλ―Έν„°
- `word_ngrams`: λ‹¨μ–΄ n-gram μ (κΈ°λ³Έκ°’: 1)
- `vector_dim`: λ²΅ν„° μ°¨μ› (κΈ°λ³Έκ°’: 100)

---

## 1οΈβƒ£2οΈβƒ£ Object2Vec (μ„λ² λ”©)

### π”΄ ν•„μ ν•μ΄νΌνλΌλ―Έν„°
- **`enc0_network`**: μ²« λ²μ§Έ μ…λ ¥μ μΈμ½”λ” λ„¤νΈμ›ν¬ νƒ€μ…
- **`enc1_network`**: λ‘ λ²μ§Έ μ…λ ¥μ μΈμ½”λ” λ„¤νΈμ›ν¬ νƒ€μ…

### π΅ μ£Όμ” μ„ νƒ ν•μ΄νΌνλΌλ―Έν„°
- `epochs`: ν›λ ¨ μ—ν¬ν¬ μ (κΈ°λ³Έκ°’: 30)
- `learning_rate`: ν•™μµλ¥  (κΈ°λ³Έκ°’: 0.001)
- `mlp_layers`: MLP λ μ΄μ–΄ μ (κΈ°λ³Έκ°’: 2)
- `mlp_dim`: MLP μ°¨μ› (κΈ°λ³Έκ°’: 1024)
- `optimizer`: μµμ ν™”κΈ° (κΈ°λ³Έκ°’: adam)

---

## 1οΈβƒ£3οΈβƒ£ IP Insights (μ΄μƒ νƒμ§€)

### π”΄ ν•„μ ν•μ΄νΌνλΌλ―Έν„°
- **`num_entity_vectors`**: μ—”ν‹°ν‹° λ²΅ν„° μ
- **`vector_dim`**: λ²΅ν„° μ°¨μ›μ

### π΅ μ£Όμ” μ„ νƒ ν•μ΄νΌνλΌλ―Έν„°
- `epochs`: ν›λ ¨ μ—ν¬ν¬ μ (κΈ°λ³Έκ°’: 5)
- `learning_rate`: ν•™μµλ¥  (κΈ°λ³Έκ°’: 0.01)
- `batch_size`: λ°°μΉ ν¬κΈ° (κΈ°λ³Έκ°’: 32)

---

## π― ν•µμ‹¬ ν¬μΈνΈ μ •λ¦¬

### β… μ¤‘μ”ν• μμ •μ‚¬ν•­ (AWS κ³µμ‹ λ¬Έμ„ κ²€μ¦)

1. **XGBoost `num_round`**: multi:softprobλΏλ§ μ•„λ‹λΌ **λ¨λ“  μƒν™©μ—μ„ ν•„μ**
2. **Linear Learner `predictor_type`**: **ν•­μƒ ν•„μ**λ΅ μ„¤μ •ν•΄μ•Ό ν•¨
3. **μ΅°κ±΄λ¶€ ν•„μ νλΌλ―Έν„°λ“¤**: νΉμ • λ¨λ“λ‚ λ©μ ν•¨μ μ‚¬μ© μ‹μ—λ§ ν•„μ

### π’΅ μ‹¤λ¬΄ ν

- **ν•μ΄νΌνλΌλ―Έν„° νλ‹**: SageMaker Automatic Model Tuning ν™μ© μ¶”μ²
- **κΈ°λ³Έκ°’ ν™μ©**: μ²μμ—λ” κΈ°λ³Έκ°’μΌλ΅ μ‹μ‘ν• ν›„ μ μ§„μ μΌλ΅ νλ‹
- **λ¬Έμ„ ν™•μΈ**: AWS κ³µμ‹ λ¬Έμ„μ—μ„ μµμ‹  μ •λ³΄ ν™•μΈ ν•„μ

---

## π”— μ°Έκ³  μλ£

μ΄ κ°€μ΄λ“λ” AWS κ³µμ‹ λ¬Έμ„λ¥Ό κΈ°λ°μΌλ΅ μ‘μ„±λμ—μΌλ©°, μ‹¤μ  μ΄μ ν™κ²½μ—μ„ κ²€μ¦λ μ •λ³΄μ…λ‹λ‹¤. 

SageMakerλ¥Ό ν™μ©ν• λ¨Έμ‹ λ¬λ‹ ν”„λ΅μ νΈμ— λ„μ›€μ΄ λκΈΈ λ°”λλ‹λ‹¤! π€

μ§λ¬Έμ΄λ‚ κ¶κΈν• μ μ΄ μμΌμ‹λ©΄ λ“κΈ€λ΅ λ‚¨κ²¨μ£Όμ„Έμ”! π

---

## π“± ν•΄μ‹νƒκ·Έ

#AWS #SageMaker #λ¨Έμ‹ λ¬λ‹ #ν•μ΄νΌνλΌλ―Έν„° #XGBoost #LinearLearner #ν΄λΌμ°λ“ML #λ°μ΄ν„°μ‚¬μ΄μ–Έμ¤ #AIκ°λ° #MLOps