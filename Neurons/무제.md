질문 2오답

An electronics manufacturing company is building an image classification model to detect whether a circuit board is defective or not. To decrease training time, a Machine Learning Specialist implemented transfer learning using 300 images on a pre-trained neural network obtained from a partner company. The company requires a model accuracy of no less than 95% to be feasible. The Specialist conducted a full grid search through a wide hyperparameter space. However, the optimal values returned only 73% and 72% accuracy on the training and validation set, respectively.

How can the Specialist increase the model accuracy?

Regularize the model by randomly dropping nodes.

Increase the variance using a pre-trained neural network with more layers for transfer learning.

Collect additional images and add them to the training data to decrease the bias, then retrain the model using transfer learning.

Use Amazon SageMaker’s automatic model tuning to find the best hyperparameter values for the model.

전반적인 설명

In transfer learning, the network is initialized with pre-trained weights and just the top fully connected layer is initialized with random weights. Then, the whole network is fine-tuned with new data. In this mode, training time will be reduced because the network already has prior knowledge of a former problem, and you won't have to train a model from scratch.

In simpler words, you can reuse a model trained to solve a certain task as the foundation of a new model for another task.

In the scenario, a pre-trained neural network used to identify defects in circuit boards was repurposed to solve a similar task, however, the tolerable accuracy required was not met. Based on the given accuracy scores, we can infer that the model is underfitting. Underfitting is the condition where model performance for training and validation data is poor. Bias is an error that arises when a model simplifies its assumptions towards a target variable. Variance, on the other hand, is the error you get when a model has become too sensitive to small fluctuations on unseen data.

Remember that a high-bias model is an underfitting model, whereas a high-variance model is an overfitting model. A balanced model has a low bias and low variance.

![](https://docs.aws.amazon.com/machine-learning/latest/dg/images/mlconcepts_image5.png)

To reduce the bias error, we can try adding more images to the training data by either collecting more images or generating them from the existing dataset through data augmentation methods.

Hence, the correct answer is: **Collect additional images and add them to the training data to decrease the bias, then retrain the model using transfer learning.**

The option that says: **Use Amazon SageMaker’s automatic model tuning to find the best hyperparameter values for the model** is incorrect. The automatic model tuning is just a feature of Amazon SageMaker that can help you save time searching for the optimal hyperparameter values for a model. Since an extensive grid search has already been done, it is unlikely that you'll find better hyperparameter values that would significantly increase the model's accuracy.

The option that says: **Increase the variance using a pre-trained neural network with more layers for transfer learning** is incorrect. The number of layers needed for a neural network largely depends on the complexity of the problem you are trying to solve. You have to find a sufficient number of layers for a particular problem. Adding more layers won't always result in an increase in model accuracy. In fact, having a number of layers more than what is needed could do more harm (overfitting) than good.

The option that says: **Regularize the model by randomly dropping nodes** is incorrect. Regularizing the model in this scenario will cause it to generalize poorer.