---

title: etl-stepfunctions-glue-workflow
created: 2025-08-25
modified: 2025-08-25
tags:
- service/stepfunctions
- service/glue
- workflow/orchestration
- constraint/multiple-datasets
- usecase/etl-pipeline
aliases: ["ETL Workflow", "Step Functions ETL", "Multi-Dataset Processing"]

---

# AWS Step Functionsì™€ Glueë¥¼ í™œìš©í•œ ë‹¤ì¤‘ ë°ì´í„°ì…‹ ETL ì›Œí¬í”Œë¡œìš°

## ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸

ì—¬ëŸ¬ ë°ì´í„°ì…‹ì´ ëª¨ë‘ ì¤€ë¹„ëœ í›„ í…Œë¼ë°”ì´íŠ¸ê¸‰ ETL ì‘ì—…ì„ ìˆ˜í–‰í•´ì•¼ í•˜ëŠ” ê²½ìš°, Step Functionsë¡œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•˜ê³  Glueë¡œ ì‹¤ì œ ë°ì´í„° ì¡°ì¸ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.

## ğŸ“ ì„¤ëª…

### Step Functions + Glueê°€ ë³µì¡í•œ ETL ì›Œí¬í”Œë¡œìš°ì— ì í•©í•œ ì´ìœ 

**Step Functions**ëŠ” ì—¬ëŸ¬ AWS ì„œë¹„ìŠ¤ë¥¼ ì—°ê²°í•˜ì—¬ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•˜ëŠ” ì„œë²„ë¦¬ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. íŠ¹íˆ ì¡°ê±´ë¶€ ëŒ€ê¸°, ìƒíƒœ ì¶”ì , ì˜¤ë¥˜ ì²˜ë¦¬ê°€ í•„ìš”í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ê°•ë ¥í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

**AWS Glue**ëŠ” Apache Spark ê¸°ë°˜ì˜ ì™„ì „ ê´€ë¦¬í˜• ETL ì„œë¹„ìŠ¤ë¡œ, í…Œë¼ë°”ì´íŠ¸ê¸‰ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì„œë²„ë¦¬ìŠ¤ í™˜ê²½ì—ì„œ ìë™ ìŠ¤ì¼€ì¼ë§ì„ í†µí•´ ë¹„ìš© íš¨ìœ¨ì ì¸ ë°ì´í„° ë³€í™˜ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì•„í‚¤í…ì²˜ í”Œë¡œìš°

```
S3 ë°ì´í„°ì…‹ A ì—…ë¡œë“œ â†’ Lambda íŠ¸ë¦¬ê±° â†’ Step Functions ì‹œì‘
                                      â†“
S3 ë°ì´í„°ì…‹ B ì—…ë¡œë“œ â†’ Lambda íŠ¸ë¦¬ê±° â†’ [ìƒíƒœ ì—…ë°ì´íŠ¸]
                                      â†“
S3 ë°ì´í„°ì…‹ C ì—…ë¡œë“œ â†’ Lambda íŠ¸ë¦¬ê±° â†’ [ëª¨ë“  ë°ì´í„°ì…‹ í™•ì¸]
                                      â†“
                              [ì¡°ê±´ ë§Œì¡± ì‹œ Glue ETL ì‹¤í–‰]
                                      â†“
                              [í…Œë¼ë°”ì´íŠ¸ê¸‰ ë°ì´í„° ì¡°ì¸ ì²˜ë¦¬]
                                      â†“
                              [ê²°ê³¼ë¥¼ S3ì— ì €ì¥]
                                      â†“
                         [ì‹¤íŒ¨ ì‹œ CloudWatch â†’ SNS ì•Œë¦¼]
```

### Trade-offs ê³ ë ¤ì‚¬í•­

**Step Functions + Glue ì¥ì **:
- ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ë¡œì§ì„ ì‹œê°ì ìœ¼ë¡œ ê´€ë¦¬ ê°€ëŠ¥
- ì„œë²„ë¦¬ìŠ¤ í™˜ê²½ìœ¼ë¡œ ì¸í”„ë¼ ê´€ë¦¬ ë¶ˆí•„ìš”
- í…Œë¼ë°”ì´íŠ¸ê¸‰ ë°ì´í„° ì²˜ë¦¬ì— ìµœì í™”ëœ ì„±ëŠ¥
- ìë™ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ë¹„ìš© íš¨ìœ¨ì„± í™•ë³´
- ìƒíƒœ ì¶”ì  ë° ì˜¤ë¥˜ ì²˜ë¦¬ ê¸°ëŠ¥ ë‚´ì¥

**Step Functions + Glue ë‹¨ì **:
- ì›Œí¬í”Œë¡œìš° ë³µì¡ì„± ì¦ê°€ ì‹œ ë””ë²„ê¹… ì–´ë ¤ì›€
- Cold Start ì§€ì—° ì‹œê°„ ì¡´ì¬
- ì‹¤ì‹œê°„ ì²˜ë¦¬ë³´ë‹¤ëŠ” ë°°ì¹˜ ì²˜ë¦¬ì— ì í•©

**AWS Batch ì¥ì **:
- ì»¨í…Œì´ë„ˆ ê¸°ë°˜ìœ¼ë¡œ í™˜ê²½ ììœ ë„ ë†’ìŒ
- CPU ì§‘ì•½ì  ê³„ì‚° ì‘ì—…ì— íŠ¹í™”
- ëŒ€ëŸ‰ ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”

**AWS Batch ë‹¨ì **:
- ì´ë²¤íŠ¸ ê¸°ë°˜ íŠ¸ë¦¬ê±° êµ¬ì„± ë³µì¡
- ì¡°ê±´ë¶€ ì›Œí¬í”Œë¡œìš° ë¡œì§ êµ¬í˜„ ì–´ë ¤ì›€
- ìƒíƒœ ê´€ë¦¬ ê¸°ëŠ¥ ë¶€ì¡±

## ğŸ” ì£¼ìš”ê°œë…

### ì„œë¹„ìŠ¤ë³„ ì—­í•  ë¶„ë‹´

- **Step Functions**: ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜, ì¡°ê±´ë¶€ ëŒ€ê¸°, ìƒíƒœ ê´€ë¦¬, ì˜¤ë¥˜ ì²˜ë¦¬
- **AWS Glue**: ì‹¤ì œ ETL ì‘ì—… ì‹¤í–‰, ëŒ€ìš©ëŸ‰ ë°ì´í„° ì¡°ì¸, Spark ê¸°ë°˜ ì²˜ë¦¬
- **AWS Batch**: ìˆœìˆ˜ ê³„ì‚° ì‘ì—…ì˜ ëŒ€ëŸ‰ ë³‘ë ¬ ì²˜ë¦¬ (CPU ì§‘ì•½ì )
- **Lambda**: ê°€ë²¼ìš´ íŠ¸ë¦¬ê±° ë° ê°„ë‹¨í•œ ì²˜ë¦¬ ë¡œì§

### ì‹¤ì „ ì ìš© ì‹œë‚˜ë¦¬ì˜¤

- **ì¼ì¼ ë°ì´í„° íŒŒì´í”„ë¼ì¸**: ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ì˜¤ëŠ” ë°ì´í„°ë¥¼ ëª¨ë‘ ìˆ˜ì§‘í•œ í›„ í†µí•© ë¶„ì„
- **ê¸ˆìœµ ë¦¬ìŠ¤í¬ ë¶„ì„**: ì‹œì¥ ë°ì´í„°, ê±°ë˜ ë°ì´í„°, ê³ ê° ë°ì´í„°ê°€ ëª¨ë‘ ì¤€ë¹„ëœ í›„ ì¢…í•© ë¶„ì„
- **IoT ì„¼ì„œ ë°ì´í„° í†µí•©**: ë‹¤ì–‘í•œ ì„¼ì„œì—ì„œ ì˜¤ëŠ” ë°ì´í„°ë¥¼ ì‹œê°„ëŒ€ë³„ë¡œ ìˆ˜ì§‘í•˜ì—¬ í†µí•© ì²˜ë¦¬

## ğŸ“ ê´€ë ¨ ë¬¸ì œ

**Question:** A Machine Learning Specialist is developing a daily ETL workflow containing multiple ETL jobs. The workflow consists of the following processes: Start the workflow as soon as data is uploaded to Amazon S3. When all the datasets are available in Amazon S3, start an ETL job to join the uploaded datasets with multiple terabyte-sized datasets already stored in Amazon S3. Store the results of joining datasets in Amazon S3. If one of the jobs fails, send a notification to the Administrator. Which configuration will meet these requirements?

**Options:**

- A) Use AWS Lambda to trigger an AWS Step Functions workflow to wait for dataset uploads to complete in Amazon S3. Use AWS Glue to join the datasets. Use an Amazon CloudWatch alarm to send an SNS notification to the Administrator in the case of a failure.
- B) Develop the ETL workflow using AWS Lambda to start an Amazon SageMaker notebook instance. Use a lifecycle configuration script to join the datasets and persist the results in Amazon S3. Use an Amazon CloudWatch alarm to send an SNS notification to the Administrator in the case of a failure.
- C) Develop the ETL workflow using AWS Batch to trigger the start of ETL jobs when data is uploaded to Amazon S3. Use AWS Glue to join the datasets in Amazon S3. Use an Amazon CloudWatch alarm to send an SNS notification to the Administrator in the case of a failure.
- D) Use AWS Lambda to chain other Lambda functions to read and join the datasets in Amazon S3 as soon as the data is uploaded to Amazon S3. Use an Amazon CloudWatch alarm to send an SNS notification to the Administrator in the case of a failure.

**ì •ë‹µ: A) AWS Lambda + Step Functions + Glue ì¡°í•©**

ğŸ’¡ ì¶”ê°€ ì„¤ëª…:

- **B) SageMaker ì˜µì…˜** - SageMakerëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨/ì¶”ë¡ ìš©ì´ë©° ETL ì‘ì—…ì—ëŠ” ë¶€ì í•©
- **C) Batch ì˜µì…˜** - ì´ë²¤íŠ¸ ê¸°ë°˜ íŠ¸ë¦¬ê±°ì™€ ì¡°ê±´ë¶€ ëŒ€ê¸° ë¡œì§ êµ¬í˜„ì´ ë³µì¡í•˜ê³  ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ê¸°ëŠ¥ ë¶€ì¡±
- **D) Lambda ì²´ì´ë‹** - Lambdaì˜ 15ë¶„ ì‹¤í–‰ ì œí•œê³¼ ë©”ëª¨ë¦¬ ì œí•œìœ¼ë¡œ í…Œë¼ë°”ì´íŠ¸ê¸‰ ë°ì´í„° ì²˜ë¦¬ ë¶ˆê°€ëŠ¥