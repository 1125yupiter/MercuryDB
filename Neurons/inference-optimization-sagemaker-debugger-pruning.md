---

title: inference-optimization-sagemaker-debugger-pruning
created: 2025-08-27
modified: 2025-08-27
tags:
- service/sagemaker-debugger
- technique/model-pruning
- constraint/low-latency
- usecase/autonomous-vehicle
- performance/inference-optimization
aliases: ["sagemaker-pruning", "model-optimization", "inference-speedup"]

---

# ììœ¨ì£¼í–‰ì°¨ CNN ëª¨ë¸ì˜ ì¶”ë¡  ì‹œê°„ ìµœì í™”ë¥¼ ìœ„í•œ SageMaker Debuggerì™€ ëª¨ë¸ í”„ë£¨ë‹

## ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸

ììœ¨ì£¼í–‰ê³¼ ê°™ì´ ë‚®ì€ ì§€ì—°ì‹œê°„ì´ ìš”êµ¬ë˜ëŠ” í™˜ê²½ì—ì„œ CNN ëª¨ë¸ì˜ ì¶”ë¡  ì„±ëŠ¥ì„ ê°œì„ í•˜ê³ ì í•˜ëŠ” ê²½ìš°, SageMaker Debuggerë¡œ ëª¨ë¸ ë‚´ë¶€ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ ì¤‘ìš”ë„ê°€ ë‚®ì€ í•„í„°ë¥¼ ì‹ë³„í•˜ê³  í”„ë£¨ë‹ì„ í†µí•´ ëª¨ë¸ì„ ê²½ëŸ‰í™”í•  ìˆ˜ ìˆë‹¤.

## ğŸ“ ì„¤ëª…

### SageMaker Debuggerê°€ ëª¨ë¸ ìµœì í™”ì— ì í•©í•œ ì´ìœ 

SageMaker DebuggerëŠ” í›ˆë ¨ ê³¼ì •ì—ì„œ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜, ê¸°ìš¸ê¸°, í¸í–¥, í™œì„±í™” ì¶œë ¥ì— ëŒ€í•œ ìƒì„¸í•œ ê°€ì‹œì„±ì„ ì œê³µí•œë‹¤. ì´ë¥¼ í†µí•´ ê° ë ˆì´ì–´ì™€ í•„í„°ì˜ ì¤‘ìš”ë„ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ ìˆìœ¼ë©°, ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ ì ì€ êµ¬ì„± ìš”ì†Œë¥¼ ì‹ë³„í•  ìˆ˜ ìˆë‹¤. íŠ¹íˆ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ì˜ í•„í„°ë³„ í™œì„±í™” íŒ¨í„´ê³¼ ê°€ì¤‘ì¹˜ ë¶„í¬ë¥¼ ë¶„ì„í•˜ì—¬ í”„ë£¨ë‹ ëŒ€ìƒì„ ê³¼í•™ì ìœ¼ë¡œ ì„ ì •í•  ìˆ˜ ìˆë‹¤.

### ì•„í‚¤í…ì²˜ í”Œë¡œìš°

```
ê¸°ì¡´ í›ˆë ¨ëœ CNN ëª¨ë¸
    â†“
SageMaker Debuggerë¡œ í…ì„œ ë°ì´í„° ìˆ˜ì§‘
    â†“
ê°€ì¤‘ì¹˜/í™œì„±í™”/ê¸°ìš¸ê¸° ë¶„ì„
    â†“
í•„í„° ì¤‘ìš”ë„ ë­í‚¹ ê³„ì‚°
    â†“
ë‚®ì€ ìˆœìœ„ í•„í„° ì‹ë³„ ë° ì œê±° (í”„ë£¨ë‹)
    â†“
í”„ë£¨ë‹ëœ ëª¨ë¸ë¡œ ì¬í›ˆë ¨ (Fine-tuning)
    â†“
ì¶”ë¡  ì†ë„ í–¥ìƒëœ ê²½ëŸ‰í™” ëª¨ë¸ ë°°í¬
```

### Trade-offs ê³ ë ¤ì‚¬í•­

**SageMaker Debugger + í”„ë£¨ë‹ ì¥ì **:
- ëª¨ë¸ ë‚´ë¶€ êµ¬ì¡°ì— ëŒ€í•œ ê¹Šì´ ìˆëŠ” ë¶„ì„ ì œê³µ
- ê·¼ë³¸ì ì¸ ëª¨ë¸ ê²½ëŸ‰í™”ë¥¼ í†µí•œ ëŒ€í­ì ì¸ ì¶”ë¡  ì†ë„ í–¥ìƒ
- ê³¼í•™ì ì´ê³  ì²´ê³„ì ì¸ ìµœì í™” ì ‘ê·¼ë²•
- ëª¨ë¸ ì •í™•ë„ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ë©´ì„œ ì„±ëŠ¥ ê°œì„ 

**SageMaker Debugger + í”„ë£¨ë‹ ë‹¨ì **:
- ë¶„ì„ ë° ì¬í›ˆë ¨ì— ì¶”ê°€ ì‹œê°„ê³¼ ë¹„ìš© í•„ìš”
- í”„ë£¨ë‹ ì •ë„ ê²°ì •ì„ ìœ„í•œ ì „ë¬¸ ì§€ì‹ ìš”êµ¬
- ê³¼ë„í•œ í”„ë£¨ë‹ ì‹œ ì •í™•ë„ ì†ì‹¤ ìœ„í—˜

**SageMaker Model Monitor + í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • ì¥ì **:
- ë°°í¬ í›„ ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- ë¹ ë¥¸ íŒŒë¼ë¯¸í„° ì¡°ì •ìœ¼ë¡œ ì¦‰ê°ì ì¸ ê²°ê³¼ í™•ì¸

**SageMaker Model Monitor + í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • ë‹¨ì **:
- ëª¨ë¸ êµ¬ì¡° ìì²´ëŠ” ë³€ê²½ë˜ì§€ ì•Šì•„ ê·¼ë³¸ì  ê°œì„  í•œê³„
- í‘œë©´ì ì¸ ë©”íŠ¸ë¦­ë§Œ ì œê³µí•˜ì—¬ ìµœì í™” ë°©í–¥ì„± ë¶€ì¡±
- ììœ¨ì£¼í–‰ê³¼ ê°™ì€ ê·¹ì €ì§€ì—° ìš”êµ¬ì‚¬í•­ì— ë¶€ì í•©

## ğŸ” ì£¼ìš”ê°œë…

### í•µì‹¬ ê°œë… ë¹„êµ

- **Model Monitoring**: ë°°í¬ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ ì§€í‘œë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê´€ì°°í•˜ëŠ” ê²ƒìœ¼ë¡œ, ë¬¸ì œ ë°œìƒì„ ê°ì§€í•˜ì§€ë§Œ í•´ê²°ì±…ì€ ì œì‹œí•˜ì§€ ì•ŠìŒ
- **Model Debugging**: í›ˆë ¨ ê³¼ì •ì˜ í…ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•˜ì—¬ ëª¨ë¸ ë‚´ë¶€ êµ¬ì¡°ì™€ ì„±ëŠ¥ ë³‘ëª©ì ì„ ì‹ë³„í•˜ëŠ” ê³¼ì •
- **Model Pruning**: ëª¨ë¸ì—ì„œ ì¤‘ìš”ë„ê°€ ë‚®ì€ ë‰´ëŸ°, í•„í„°, ì—°ê²°ì„ ì œê±°í•˜ì—¬ ëª¨ë¸ í¬ê¸°ì™€ ì—°ì‚°ëŸ‰ì„ ì¤„ì´ëŠ” ìµœì í™” ê¸°ë²•

### ì‹¤ì „ ì ìš©

- **ììœ¨ì£¼í–‰ ì°¨ëŸ‰**: millisecond ë‹¨ìœ„ì˜ ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ì™€ ê²½ë¡œ ê³„íšì„ ìœ„í•œ CNN ëª¨ë¸ ìµœì í™”
- **ì‹¤ì‹œê°„ ì˜ìƒ ë¶„ì„**: ë³´ì•ˆ ì¹´ë©”ë¼ë‚˜ ë“œë¡ ì˜ ì‹¤ì‹œê°„ ì˜ìƒ ì²˜ë¦¬ì—ì„œ ë‚®ì€ ì§€ì—°ì‹œê°„ ìš”êµ¬
- **ëª¨ë°”ì¼ ë””ë°”ì´ìŠ¤**: ì œí•œëœ ì—°ì‚° ìì› í™˜ê²½ì—ì„œ íš¨ìœ¨ì ì¸ ì¶”ë¡ ì„ ìœ„í•œ ëª¨ë¸ ê²½ëŸ‰í™”

## ğŸ“ ê´€ë ¨ ë¬¸ì œ

**Question:** An automotive company is using computer vision in its autonomous cars. The company has trained its models successfully by using transfer learning from a convolutional neural network (CNN). The models are trained with PyTorch through the use of the Amazon SageMaker SDK. The company wants to reduce the time that is required for performing inferences, given the low latency that is required for self-driving. Which solution should the company use to evaluate and improve the performance of the models?

**Options:**

- A) Use Amazon CloudWatch algorithm metrics for visibility into the SageMaker training weights, gradients, biases, and activation outputs. Compute the filter ranks based on this information. Apply pruning to remove the low-ranking filters. Set the new weights. Run a new training job with the pruned model.
- B) Use SageMaker Debugger for visibility into the training weights, gradients, biases, and activation outputs. Adjust the model hyperparameters, and look for lower inference times. Run a new training job.
- C) Use SageMaker Debugger for visibility into the training weights, gradients, biases, and activation outputs. Compute the filter ranks based on this information. Apply pruning to remove the low-ranking filters. Set the new weights. Run a new training job with the pruned model.
- D) Use SageMaker Model Monitor for visibility into the ModelLatency metric and OverheadLatency metric of the model after the model is deployed. Adjust the model hyperparameters, and look for lower inference times. Run a new training job.

**ì •ë‹µ: C) SageMaker Debugger + ëª¨ë¸ í”„ë£¨ë‹**

ğŸ’¡ ì¶”ê°€ ì„¤ëª…:

- **Aì˜µì…˜ (CloudWatch)** - CloudWatchëŠ” ì£¼ë¡œ ëª¨ë‹ˆí„°ë§ê³¼ ë¡œê¹… ë„êµ¬ë¡œ ëª¨ë¸ì˜ ë‚´ë¶€ êµ¬ì¡° ë¶„ì„ì— ì í•©í•˜ì§€ ì•Šìœ¼ë©°, ê°€ì¤‘ì¹˜ë‚˜ í™œì„±í™” ì¶œë ¥ì— ëŒ€í•œ ìƒì„¸í•œ ê°€ì‹œì„±ì„ ì œê³µí•˜ì§€ ì•ŠìŒ
- **Bì˜µì…˜ (Debugger + í•˜ì´í¼íŒŒë¼ë¯¸í„°)** - SageMaker DebuggerëŠ” ì˜¬ë°”ë¥¸ ë„êµ¬ì´ì§€ë§Œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •ë§Œìœ¼ë¡œëŠ” ê·¼ë³¸ì ì¸ ì¶”ë¡  ì†ë„ ê°œì„ ì— í•œê³„ê°€ ìˆì–´ ììœ¨ì£¼í–‰ì˜ ê·¹ì €ì§€ì—° ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ê¸° ì–´ë ¤ì›€
- **Dì˜µì…˜ (Model Monitor + í•˜ì´í¼íŒŒë¼ë¯¸í„°)** - Model MonitorëŠ” ë°°í¬ í›„ ëª¨ë‹ˆí„°ë§ ì „ìš© ë„êµ¬ë¡œ ì§€ì—°ì‹œê°„ ìˆ˜ì¹˜ë§Œ ì œê³µí•  ë¿ ëª¨ë¸ ìµœì í™”ë¥¼ ìœ„í•œ êµ¬ì²´ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•˜ì§€ ëª»í•˜ë©°, í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •ì˜ íš¨ê³¼ë„ ì œí•œì 