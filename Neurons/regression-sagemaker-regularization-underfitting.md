---

title: regression-sagemaker-regularization-underfitting
created: 2025-08-18
modified: 2025-08-18
tags:
- problem/regression
- service/sagemaker
- technique/regularization
- constraint/underfitting
- usecase/energy-prediction
aliases: ["L1-regularization", "underfitting-solution", "lasso-ridge"]

---

# νκ·€ λ¨λΈμ—μ„ L1 μ •κ·ν™”λ΅ μΈν• μ–Έλ”ν”Όν… ν•΄κ²° λ°©μ•

## π― ν•µμ‹¬ ν¬μΈνΈ

L1 μ •κ·ν™”κ°€ λ„λ¬΄ κ°•ν•κ² μ μ©λμ–΄ λ¨λΈμ΄ μ–Έλ”ν”Όν…λ κ²½μ°, L1 μ •κ·ν™” νλΌλ―Έν„°λ¥Ό μ¤„μ΄κ±°λ‚ L2 μ •κ·ν™”λ΅ μ „ν™ν•μ—¬ μμΈ΅ μ„±λ¥μ„ κ°μ„ ν•  μ μλ‹¤.

## π“ μ„¤λ…

### L1 μ •κ·ν™”κ°€ μ¤λ§νΈν™ μ—λ„μ§€ μμΈ΅μ—μ„ μ–Έλ”ν”Όν…μ„ μ•ΌκΈ°ν•λ” μ΄μ 

L1 μ •κ·ν™”(Lasso)λ” νΉμ„± μ„ νƒ ν¨κ³Όλ¥Ό ν†µν•΄ λ¨λΈμ ν•΄μ„μ„±μ„ ν–¥μƒμ‹ν‚¤μ§€λ§, λ„λ¬΄ κ°•ν•κ² μ μ©λλ©΄ μ¤‘μ”ν• νΉμ„±λ“¤κΉμ§€ μ κ±°ν•μ—¬ μ–Έλ”ν”Όν…μ„ λ°μƒμ‹ν‚µλ‹λ‹¤. μ¤λ§νΈν™ ν™κ²½μ—μ„λ” μ¨λ„, μµλ„, μ΅°λ…, κΈ°κΈ° μ‚¬μ© ν¨ν„΄ λ“± λ‹¤μ–‘ν• ν™κ²½ λ° μ‚¬μ© νΉμ„±μ΄ λ¨λ‘ μ—λ„μ§€ μ†λΉ„μ— μν–¥μ„ λ―ΈμΉλ”λ°, κ³Όλ„ν• L1 μ •κ·ν™”λ΅ μΈν•΄ μ΄λ¬ν• μ¤‘μ” νΉμ„±λ“¤μ κ³„μκ°€ 0μ΄ λμ–΄ λ²„λ¦½λ‹λ‹¤.

### μ •κ·ν™” λ°©μ‹λ³„ νΉμ§• λΉ„κµ

**L1 μ •κ·ν™” (Lasso)**
- κ³„μμ μ λ“κ°’μ— νλ„ν‹° λ¶€μ—¬
- λ¶ν•„μ”ν• νΉμ„±μ κ³„μλ¥Ό μ •ν™•ν 0μΌλ΅ λ§λ“¦
- μλ™ νΉμ„± μ„ νƒ ν¨κ³Ό
- ν¬μ†ν•(sparse) λ¨λΈ μƒμ„±

**L2 μ •κ·ν™” (Ridge)**
- κ³„μμ μ κ³±μ— νλ„ν‹° λ¶€μ—¬
- κ³„μλ¥Ό 0μ— κ°€κΉκ² λ§λ“¤μ§€λ§ μ™„μ „ν μ κ±°ν•μ§€λ” μ•μ
- λ¨λ“  νΉμ„±μ„ μΌμ • μμ¤€ μ μ§€
- λ‹¤μ¤‘κ³µμ„ μ„± λ¬Έμ  μ™„ν™”

### μ•„ν‚¤ν…μ² ν”λ΅μ°

```
λ°μ΄ν„° μμ§‘ (ν™κ²½/μ‚¬μ© νΉμ„±)
         β†“
νΉμ„± μ—”μ§€λ‹μ–΄λ§ (AWS Glue)
         β†“
λ¨λΈ ν•™μµ (SageMaker Linear Learner)
         β†“
μ •κ·ν™” νλΌλ―Έν„° μ΅°μ •
    β†™        β†
L1 κ°μ†    L2 μ „ν™
    β†        β†™
μ„±λ¥ ν–¥μƒλ μμΈ΅ λ¨λΈ
```

### Trade-offs κ³ λ ¤μ‚¬ν•­

**L1 μ •κ·ν™” νλΌλ―Έν„° κ°μ† μ¥μ **:
- λ” λ§μ€ νΉμ„± ν™μ© κ°€λ¥
- μ–Έλ”ν”Όν… λ¬Έμ  μ§μ ‘μ  ν•΄κ²°
- μ—¬μ „ν μΌμ • μμ¤€μ νΉμ„± μ„ νƒ ν¨κ³Ό μ μ§€
- SageMaker λ‚΄μ¥ μµμ ν™” λ„κµ¬ ν™μ© κ°€λ¥

**L1 μ •κ·ν™” νλΌλ―Έν„° κ°μ† λ‹¨μ **:
- κ³Όλ„ν•κ² μ¤„μ΄λ©΄ μ¤λ²„ν”Όν… μ„ν—
- λ¨λΈ ν•΄μ„μ„± λ‹¤μ† κ°μ†
- μµμ  νλΌλ―Έν„° μ°ΎκΈ° μ„ν• μ¶”κ°€ νλ‹ ν•„μ”

**L2 μ •κ·ν™” μ „ν™ μ¥μ **:
- λ¨λ“  νΉμ„±μ κΈ°μ—¬λ„ μ μ§€
- λ³µμ΅ν• λ°μ΄ν„°μ…‹μ—μ„ μΌλ°ν™” μ„±λ¥ μ°μ
- λ‹¤μ¤‘κ³µμ„ μ„± λ¬Έμ  μ™„ν™”
- μ•μ •μ μΈ ν•™μµ κ³Όμ •

**L2 μ •κ·ν™” μ „ν™ λ‹¨μ **:
- μλ™ νΉμ„± μ„ νƒ ν¨κ³Ό μ—†μ
- λ¶ν•„μ”ν• νΉμ„±κΉμ§€ ν¬ν•¨ν•μ—¬ ν•΄μ„μ„± μ €ν•
- λ¨λΈ λ³µμ΅λ„ μ¦κ°€

## π” μ£Όμ”κ°λ…

### μ •κ·ν™” λ°©μ‹λ³„ μν•™μ  νΉμ„±

- **L1 μ •κ·ν™”**: Ξ»β‘|Ξ²αµΆ| - μ λ“κ°’ κΈ°λ° νλ„ν‹°λ΅ ν¬μ†μ„± μ΄‰μ§„
- **L2 μ •κ·ν™”**: Ξ»β‘Ξ²αµΆΒ² - μ κ³± κΈ°λ° νλ„ν‹°λ΅ κ³„μ ν¬κΈ° μ ν•

### μ‹¤μ „ μ μ© μ‹λ‚λ¦¬μ¤

- **μ¤λ§νΈν™ μ—λ„μ§€ κ΄€λ¦¬**: λ‹¤μ–‘ν• ν™κ²½ μ„Όμ„ λ°μ΄ν„° ν™μ©ν• μ‹¤μ‹κ°„ μ†λΉ„ μμΈ΅
- **IoT λ””λ°”μ΄μ¤ μµμ ν™”**: κΈ°κΈ°λ³„ μ‚¬μ© ν¨ν„΄ ν•™μµμ„ ν†µν• ν¨μ¨μ  μ—λ„μ§€ λ°°λ¶„
- **κ±΄λ¬Ό κ΄€λ¦¬ μ‹μ¤ν…**: κ³„μ λ³„, μ‹κ°„λ€λ³„ μ—λ„μ§€ μμ” μμΈ΅ λ° λΉ„μ© μµμ ν™”

## π“ κ΄€λ ¨ λ¬Έμ 

**Question:** An AI startup is developing a regression model to predict energy consumption in smart homes based on numerous environmental and usage features. To enhance model simplicity and interpretability, L1 regularization was incorporated. However, preliminary testing indicates the model is underfitting, leading to poor predictions. Which two adjustments could potentially improve the model's accuracy in this scenario?

**Options:**

- A) Increase the data sampling rate to capture more granular environmental and usage features
- B) Switch to L2 regularization in Amazon SageMaker's Linear Learner for a different penalty approach
- C) Reduce the L1 regularization parameter using Amazon SageMaker's built-in optimization
- D) Amplify the L1 regularization term with Amazon SageMaker's algorithm tuning
- E) Employ AWS Glue DataBrew to trim less significant features before modeling

**μ •λ‹µ: B, C) L2 μ •κ·ν™” μ „ν™ λ° L1 μ •κ·ν™” νλΌλ―Έν„° κ°μ†**

π’΅ μ¶”κ°€ μ„¤λ…:

- **Option A** - λ°μ΄ν„° μ„Έλ¶„ν™”λ” λ³µμ΅λ„λ§ μ¦κ°€μ‹ν‚¤κ³  μ •κ·ν™”λ΅ μΈν• μ–Έλ”ν”Όν… κ·Όλ³Έ μ›μΈμ„ ν•΄κ²°ν•μ§€ λ»ν•¨
- **Option D** - L1 μ •κ·ν™” κ°•ν™”λ” μ–Έλ”ν”Όν…μ„ λ”μ± μ•…ν™”μ‹μΌ μμΈ΅ μ„±λ¥μ„ μ €ν•μ‹ν‚΄
- **Option E** - νΉμ„± μ κ±°λ” μ •κ·ν™” νλΌλ―Έν„° μ΅°μ •κ³Ό λ¬΄κ΄€ν•λ©° μ–Έλ”ν”Όν… λ¬Έμ  ν•΄κ²°μ— μ§μ ‘μ  λ„μ›€ μ• λ¨

---