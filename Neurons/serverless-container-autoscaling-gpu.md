---

title: serverless-container-autoscaling-gpu
created: 2025-08-20
modified: 2025-08-20
tags:
- deployment/serverless
- service/fargate
- service/sagemaker
- constraint/gpu-support
- scaling/auto
aliases: ["serverless-ml", "container-gpu", "fargate-vs-sagemaker"]

---

# ì„œë²„ë¦¬ìŠ¤ ì»¨í…Œì´ë„ˆ í™˜ê²½ì—ì„œ GPU ì§€ì› ML ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬

## ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸

ì„œë²„ë¦¬ìŠ¤ í™˜ê²½ì—ì„œ Docker ì»¨í…Œì´ë„ˆë¡œ ìë™ ìŠ¤ì¼€ì¼ë§ì´ í•„ìš”í•œ ê²½ìš° AWS Fargateë¥¼ ì‚¬ìš©í•˜ê³ , GPU ì§€ì›ì´ ì¶”ê°€ë¡œ í•„ìš”í•œ ê²½ìš° Amazon SageMaker Endpointsë¥¼ í™œìš©í•  ìˆ˜ ìˆë‹¤.

## ğŸ“ ì„¤ëª…

### AWS Fargateê°€ ì„œë²„ë¦¬ìŠ¤ ì»¨í…Œì´ë„ˆ ë°°í¬ì— ì í•©í•œ ì´ìœ 

AWS FargateëŠ” ì™„ì „ ì„œë²„ë¦¬ìŠ¤ ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì—”ì§„ìœ¼ë¡œ, ì¸í”„ë¼ ê´€ë¦¬ ì—†ì´ Docker ì»¨í…Œì´ë„ˆë¥¼ ë°°í¬í•  ìˆ˜ ìˆë‹¤. Application Auto Scalingê³¼ í†µí•©í•˜ì—¬ CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ê¸°ë°˜ ìë™ ìŠ¤ì¼€ì¼ë§ì„ ì§€ì›í•˜ë©°, ì‹¤ì œ ì‚¬ìš©í•œ vCPUì™€ ë©”ëª¨ë¦¬ì— ëŒ€í•´ì„œë§Œ ê³¼ê¸ˆí•œë‹¤.

### ì•„í‚¤í…ì²˜ í”Œë¡œìš°

```
Traffic â†’ ALB â†’ ECS Service (Fargate) â†’ Auto Scaling
                     â†“
              Container Tasks â†â†’ CloudWatch Metrics
                     â†“
              Scale Up/Down based on CPU/Memory
```

### GPU ìš”êµ¬ì‚¬í•­ì´ ìˆëŠ” ê²½ìš°ì˜ ëŒ€ì•ˆ

AWS FargateëŠ” GPUë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, GPUê°€ í•„ìš”í•œ ML ì›Œí¬ë¡œë“œì˜ ê²½ìš° ë‹¤ë¥¸ ì ‘ê·¼ ë°©ì‹ì´ í•„ìš”í•˜ë‹¤:

```
ML Inference Request â†’ SageMaker Endpoint â†’ GPU Instance
                              â†“
                    Auto Scaling (Instance-based)
                              â†“
                    Custom Container (BYOC)
```

### Trade-offs ê³ ë ¤ì‚¬í•­

**AWS Fargate ì¥ì **:
- ì™„ì „ ì„œë²„ë¦¬ìŠ¤ (ì¸í”„ë¼ ê´€ë¦¬ ë¶ˆí•„ìš”)
- ìë™ ìŠ¤ì¼€ì¼ë§ ì§€ì›
- ì¢…ëŸ‰ì œ ê³¼ê¸ˆìœ¼ë¡œ ë¹„ìš© íš¨ìœ¨ì 
- í‘œì¤€ Docker ì»¨í…Œì´ë„ˆ ì™„ë²½ ì§€ì›

**AWS Fargate ë‹¨ì **:
- GPU ì§€ì› ì—†ìŒ
- ì˜êµ¬ ìŠ¤í† ë¦¬ì§€ ì œí•œ
- Cold start ì§€ì—°ì‹œê°„
- íŠ¹ì • ë„¤íŠ¸ì›Œí‚¹ ìš”êµ¬ì‚¬í•­ ì œí•œ

**SageMaker Endpoints ì¥ì **:
- GPU ì¸ìŠ¤í„´ìŠ¤ ì§€ì› (p3, p4, g4 ë“±)
- MLì— íŠ¹í™”ëœ ê¸°ëŠ¥ë“¤ (A/B í…ŒìŠ¤íŒ…, ëª¨ë¸ ëª¨ë‹ˆí„°ë§)
- ìë™ ìŠ¤ì¼€ì¼ë§ ì§€ì›
- ì‚¬ìš©ì ì •ì˜ ì»¨í…Œì´ë„ˆ ì§€ì› (BYOC)

**SageMaker Endpoints ë‹¨ì **:
- ì™„ì „ ì„œë²„ë¦¬ìŠ¤ëŠ” ì•„ë‹˜ (ìµœì†Œ ì¸ìŠ¤í„´ìŠ¤ ìœ ì§€)
- Fargate ëŒ€ë¹„ ë†’ì€ ë¹„ìš©
- ML ì´ì™¸ ìš©ë„ì—ëŠ” ê³¼ë„í•œ ê¸°ëŠ¥

## ğŸ” ì£¼ìš”ê°œë…

### ì„œë²„ë¦¬ìŠ¤ vs ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ ë¹„êµ

- **ì„œë²„ë¦¬ìŠ¤ (Fargate)**: ì¸í”„ë¼ ì™„ì „ ì¶”ìƒí™”, ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ê³¼ê¸ˆ, 0ê¹Œì§€ ìŠ¤ì¼€ì¼ ë‹¤ìš´ ê°€ëŠ¥
- **ê´€ë¦¬í˜• (ECS EC2)**: ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬ í•„ìš”, ì˜ˆì•½ ì¸ìŠ¤í„´ìŠ¤ë¡œ ë¹„ìš© ì ˆì•½ ê°€ëŠ¥, GPU ì§€ì›

### ì‹¤ì „ ì ìš©

- **ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ API**: Fargate + ALBë¡œ íŠ¸ë˜í”½ ê¸°ë°˜ ìë™ ìŠ¤ì¼€ì¼ë§
- **GPU ê¸°ë°˜ ì‹¤ì‹œê°„ ì¶”ë¡ **: SageMaker Endpoints + GPU ì¸ìŠ¤í„´ìŠ¤
- **ë°°ì¹˜ ML ì‘ì—…**: AWS Batch + GPU ì§€ì› EC2 ì¸ìŠ¤í„´ìŠ¤

## ğŸ“ ê´€ë ¨ ë¬¸ì œ

**Question:** You are designing a machine learning application that requires deploying Docker containers in a serverless environment. The application needs to scale up and down automatically based on the incoming traffic. Which AWS service is most appropriate for this requirement?

**Options:**

- A) Amazon ECS (EC2 launch type)
- B) AWS Fargate
- C) AWS Lambda
- D) Amazon EKS
- E) Amazon SageMaker Endpoints

**ì •ë‹µ: B) AWS Fargate**

ğŸ’¡ ì¶”ê°€ ì„¤ëª…:

- **Amazon ECS (EC2 launch type)** - ì»¨í…Œì´ë„ˆ ì§€ì›í•˜ì§€ë§Œ ì„œë²„ë¦¬ìŠ¤ í™˜ê²½ì´ ì•„ë‹˜ (EC2 ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬ í•„ìš”)
- **AWS Lambda** - ì„œë²„ë¦¬ìŠ¤ì´ì§€ë§Œ ì‹¤í–‰ ì‹œê°„ ì œí•œ(15ë¶„)ê³¼ íŒ¨í‚¤ì§€ í¬ê¸° ì œí•œìœ¼ë¡œ ML ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë¶€ì í•©
- **Amazon EKS** - Kubernetes ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ì´ì§€ë§Œ ì™„ì „ ì„œë²„ë¦¬ìŠ¤ê°€ ì•„ë‹ˆë©° í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ ì˜¤ë²„í—¤ë“œ ì¡´ì¬
- **Amazon SageMaker Endpoints** - GPU ì§€ì›í•˜ì§€ë§Œ ML ì „ìš©ì´ë©° ì™„ì „ ì„œë²„ë¦¬ìŠ¤ëŠ” ì•„ë‹˜ (ìµœì†Œ ì¸ìŠ¤í„´ìŠ¤ ìœ ì§€ í•„ìš”)