---
title: classification-xgboost-multiclass
created: 2025-08-16
modified: 2025-08-16
tags:
  - problem/classification
  - algorithm/xgboost
  - technique/multiclass
  - objective/softmax
  - feature/numerical
aliases:
  - xgboost-multiclass
  - multi-softmax
  - xgb-classification
---

# XGBoost ë‹¤ì¤‘ ë¶„ë¥˜ë¥¼ ìœ„í•œ Objective ì„¤ì •

## ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸

ì „ììƒê±°ë˜ ì œí’ˆ ë¶„ë¥˜ì™€ ê°™ì€ ë‹¤ì¤‘ ë¶„ë¥˜ ë¬¸ì œì—ì„œ ìˆ˜ì¹˜í˜• í”¼ì²˜ë¥¼ í™œìš©í•  ê²½ìš°, XGBoostì˜ `multi:softmax` objectiveë¡œ ë†’ì€ ì„±ëŠ¥ì˜ ë¶„ë¥˜ ëª¨ë¸ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.

## ğŸ“ ì„¤ëª…

### XGBoostê°€ ë‹¤ì¤‘ ë¶„ë¥˜ì— ì í•©í•œ ì´ìœ 

XGBoostëŠ” Gradient Boosting ê¸°ë°˜ì˜ ì•™ìƒë¸” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ìˆ˜ì¹˜í˜• ë°ì´í„°ì— íŠ¹íˆ ê°•í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ì „ììƒê±°ê±°ë˜ ì œí’ˆ ë¶„ë¥˜ ì‹œë‚˜ë¦¬ì˜¤(5,000ê°œ ì œí’ˆ, 10ê°œ ì¹´í…Œê³ ë¦¬, 20ê°œ ìˆ˜ì¹˜í˜• í”¼ì²˜)ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ì´ìœ ë¡œ ìµœì ì˜ ì„ íƒì…ë‹ˆë‹¤:

- **ìˆ˜ì¹˜í˜• ë°ì´í„° ì²˜ë¦¬ ìµœì í™”**: ì œí’ˆì½”ë“œ, ë‹¨ê°€, ì°¨ì› ë“±ì˜ ìˆ˜ì¹˜í˜• í”¼ì²˜ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬
- **ê³¼ì í•© ë°©ì§€**: ë‚´ì¥ëœ ì •ê·œí™” ê¸°ëŠ¥ìœ¼ë¡œ ì•ˆì •ì ì¸ ì„±ëŠ¥ ë³´ì¥
- **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**: ë‹¤ì–‘í•œ ì¡°ì • ì˜µì…˜ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™” ê°€ëŠ¥
- **ë¹ ë¥¸ í•™ìŠµ ì†ë„**: ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì—ì„œë„ íš¨ìœ¨ì ì¸ í•™ìŠµ

### XGBoost Objective íŒ¨í„´

```
[ë¬¸ì œìœ í˜•]:[ì²˜ë¦¬ë°©ì‹]

multi:softmax     â†’ ë‹¤ì¤‘ë¶„ë¥˜:ì†Œí”„íŠ¸ë§¥ìŠ¤(í´ë˜ìŠ¤ ë°˜í™˜)
multi:softprob    â†’ ë‹¤ì¤‘ë¶„ë¥˜:ì†Œí”„íŠ¸ë§¥ìŠ¤(í™•ë¥  ë°˜í™˜)  
binary:logistic   â†’ ì´ì§„ë¶„ë¥˜:ë¡œì§€ìŠ¤í‹±í•¨ìˆ˜
reg:squarederror  â†’ íšŒê·€:ì œê³±ì˜¤ì°¨
```

### Trade-offs ê³ ë ¤ì‚¬í•­

**XGBoost (multi:softmax) ì¥ì **:
- ìˆ˜ì¹˜í˜• ë°ì´í„°ì— ë›°ì–´ë‚œ ì„±ëŠ¥
- ê³¼ì í•© ë°©ì§€ ê¸°ëŠ¥ ë‚´ì¥
- ë¹ ë¥¸ í•™ìŠµ ë° ì˜ˆì¸¡ ì†ë„
- í•´ì„ ê°€ëŠ¥í•œ í”¼ì²˜ ì¤‘ìš”ë„ ì œê³µ

**XGBoost ë‹¨ì **:
- í…ìŠ¤íŠ¸ë‚˜ ì´ë¯¸ì§€ ë°ì´í„°ì—ëŠ” ë¶€ì í•©
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í•„ìš”
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ìƒëŒ€ì ìœ¼ë¡œ ë†’ìŒ

**K-means ë‹¨ì **:
- ë¹„ì§€ë„í•™ìŠµìœ¼ë¡œ ë¼ë²¨ ì •ë³´ í™œìš© ë¶ˆê°€
- ì œí’ˆ ë¶„ë¥˜ì— ë¶€ì í•©í•œ í´ëŸ¬ìŠ¤í„°ë§ ë°©ì‹

**CNN ë‹¨ì **:
- ìˆ˜ì¹˜í˜• í”¼ì²˜ì—ëŠ” ì˜¤ë²„ì—”ì§€ë‹ˆì–´ë§
- ì´ë¯¸ì§€ ë°ì´í„°ê°€ ì•„ë‹Œ ê²½ìš° ë¹„íš¨ìœ¨ì 

**NTM ë‹¨ì **:
- í…ìŠ¤íŠ¸ í† í”½ ëª¨ë¸ë§ ì „ìš©
- ì œí’ˆ ë¶„ë¥˜ ëª©ì ê³¼ ë¶ˆì¼ì¹˜

## ğŸ” ì£¼ìš”ê°œë…

### Objective ì„¤ì • ë¹„êµ

- **multi:softmax**: ê° ìƒ˜í”Œì— ëŒ€í•´ í•˜ë‚˜ì˜ í´ë˜ìŠ¤ ë ˆì´ë¸”ë§Œ ë°˜í™˜ (ì˜ˆ: `[2, 0, 5, 1]`)
- **multi:softprob**: ê° ìƒ˜í”Œì— ëŒ€í•´ ëª¨ë“  í´ë˜ìŠ¤ì˜ í™•ë¥  ë°˜í™˜ (ì˜ˆ: `[[0.1, 0.7, 0.2], [0.6, 0.2, 0.2]]`)

### ì‹¤ì „ ì ìš©

- **ì „ììƒê±°ë˜ ì œí’ˆ ë¶„ë¥˜**: ì œí’ˆì½”ë“œ, ê°€ê²©, ì°¨ì› ë“±ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
- **ê³ ê° ì„¸ê·¸ë©˜í…Œì´ì…˜**: êµ¬ë§¤ ì´ë ¥, ì¸êµ¬í†µê³„ë¡œ ê³ ê° ê·¸ë£¹ ë¶„ë¥˜  
- **ê¸ˆìœµ ìœ„í—˜ë„ í‰ê°€**: ì¬ë¬´ ì§€í‘œë¡œ ì‹ ìš© ë“±ê¸‰ ë¶„ë¥˜

## ğŸ“ ê´€ë ¨ ë¬¸ì œ

**Question:** A Machine Learning Specialist working for an e-commerce store needs to develop a supervised model for product categorization. The Specialist was given a CSV dataset for 5,000 products. Each product is associated with a target label representing its category (e.g., Electronics, Automotive, Office supplies, Clothing). There are a total of 10 categories and 20 numerical features that correspond to variables such as product codes, price, dimensions, and so on. Based on the given dataset, which machine learning approach should the Specialist implement?

**Options:**

- A) Train the model using the built-in K-means algorithm on Amazon SageMaker. Cluster the items into 10 groups by setting the k-parameter to 10.
- B) Use the Amazon SageMaker XGBoost algorithm that has the objective hyperparameter set to multi:softmax.
- C) Train the model using a Keras Convolutional Neural Network (CNN) on Amazon SageMaker.
- D) Use the Amazon SageMaker Neural Topic Model (NTM) algorithm and set the feature_dim hyperparameter to 2,000.

**ì •ë‹µ: B) Use the Amazon SageMaker XGBoost algorithm that has the objective hyperparameter set to multi:softmax.**

ğŸ’¡ ì¶”ê°€ ì„¤ëª…:

- **Option A (K-means)** - ë¹„ì§€ë„í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë¼ë²¨ ì •ë³´ë¥¼ í™œìš©í•  ìˆ˜ ì—†ì–´ ì§€ë„í•™ìŠµ ë¬¸ì œì— ë¶€ì í•©
- **Option C (CNN)** - ì´ë¯¸ì§€ ë°ì´í„° ì²˜ë¦¬ì— íŠ¹í™”ëœ ëª¨ë¸ë¡œ ìˆ˜ì¹˜í˜• í”¼ì²˜ ë¶„ë¥˜ì—ëŠ” ì˜¤ë²„ì—”ì§€ë‹ˆì–´ë§
- **Option D (NTM)** - í…ìŠ¤íŠ¸ í† í”½ ëª¨ë¸ë§ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì œí’ˆ ë¶„ë¥˜ ëª©ì ê³¼ ë¶ˆì¼ì¹˜

### ì„¤ì • ì˜ˆì‹œ

```python
# XGBoost ë‹¤ì¤‘ ë¶„ë¥˜ ì„¤ì •
xgb_params = {
    'objective': 'multi:softmax',  # ë‹¤ì¤‘ ë¶„ë¥˜
    'num_class': 10,              # 10ê°œ ì¹´í…Œê³ ë¦¬
    'max_depth': 6,
    'eta': 0.3,
    'subsample': 0.8
}

# í™•ë¥ ê°’ì´ í•„ìš”í•œ ê²½ìš°
xgb_params_prob = {
    'objective': 'multi:softprob',  # í™•ë¥  ë°˜í™˜
    'num_class': 10,
    'max_depth': 6,
    'eta': 0.3
}
```