---
title: migration-s3-athena-parquet.md
created: 2025-08-17
modified: 2025-08-17
tags:
- service/s3
- service/athena
- service/glue
- technique/columnar-format
- constraint/query-performance
aliases: ["csv-to-parquet", "athena parquet optimization", "s3 parquet format"]
---

# CSV ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œ Athena ì¿¼ë¦¬ ìµœì í™”ë¥¼ ìœ„í•œ Apache Parquet ë³€í™˜

## ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸

ìˆ˜ë°±ë§Œ CSV ë°ì´í„°ë¥¼ S3ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•œ ê²½ìš°, Athena ì¿¼ë¦¬ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ Apache Parquet ì»¬ëŸ¼ ê¸°ë°˜ í¬ë§·ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ìˆë‹¤.

## ğŸ“ ì„¤ëª…

### Athenaê°€ CSV ëŒ€ì‹  Parquetì— ì í•©í•œ ì´ìœ 
- CSVëŠ” **row-based í¬ë§·**ì´ë¼ ì¿¼ë¦¬ ì‹œ ì „ì²´ ë°ì´í„°ë¥¼ ìŠ¤ìº”í•´ì•¼ í•˜ë¯€ë¡œ ë¹„íš¨ìœ¨ì ì„.  
- Parquetì€ **columnar format**ìœ¼ë¡œ, í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì½ê¸° ë•Œë¬¸ì— ì¿¼ë¦¬ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë¨.  
- **Predicate Pushdown** ê¸°ëŠ¥ì„ í†µí•´ ë¶ˆí•„ìš”í•œ ë°ì´í„° ë¸”ë¡ì€ ì½ì§€ ì•Šê³  ê±´ë„ˆëœ€.  
- í‰ê· ì ìœ¼ë¡œ CSV ëŒ€ë¹„ **2ë°° ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„, 6ë°° ì ì€ ìŠ¤í† ë¦¬ì§€ ì‚¬ìš©ëŸ‰**ì„ ì œê³µ.  
- AWS Glueë¡œ CSV â†’ Parquet ë³€í™˜ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„± ê°€ëŠ¥.

### ì•„í‚¤í…ì²˜ í”Œë¡œìš°

CSV íŒŒì¼ (ìˆ˜ë°±ë§Œ ê±´) â†’ Amazon S3 ì—…ë¡œë“œ
â†“
AWS Glue ETL Job
â†“ (CSV â†’ Parquet ë³€í™˜)
Parquet íŒŒì¼ ì €ì¥ (S3, íŒŒí‹°ì…”ë‹/ì••ì¶•)
â†“
Amazon Athena / Redshift Spectrum ì¿¼ë¦¬

### Trade-offs ê³ ë ¤ì‚¬í•­

**Parquet ì¥ì **:
- ì»¬ëŸ¼ ê¸°ë°˜ ì €ì¥ìœ¼ë¡œ ì¿¼ë¦¬ ì„±ëŠ¥ ìµœì í™”
- ì €ì¥ ë¹„ìš© ì ˆê° (ì••ì¶• íš¨ìœ¨ ìš°ìˆ˜)
- Athena, Redshift Spectrum ë“±ê³¼ í˜¸í™˜

**Parquet ë‹¨ì **:
- ì´ˆê¸° ë³€í™˜ ì‘ì—… ë¹„ìš© ë°œìƒ
- ì‹¤ì‹œê°„ ë°ì´í„° ì‚½ì…ì—ëŠ” ë¶€ì í•© (ë°°ì¹˜ ì „í™˜ì— ì í•©)

**CSV (gzip) ì¥ì **:
- ë‹¨ìˆœ ì €ì¥ ë° ì••ì¶• íš¨ìœ¨ ê°œì„ 
- íŒŒì´í”„ë¼ì¸ ê°„ í˜¸í™˜ì„± ë†’ìŒ

**CSV (gzip) ë‹¨ì **:
- ì—¬ì „íˆ row-based â†’ ì¿¼ë¦¬ ì‹œ ì „ì²´ ìŠ¤ìº”
- ì„±ëŠ¥ ë° ë¹„ìš© ìµœì í™”ì— ë¶ˆë¦¬

**JSON ì¥ì **:
- ë°˜ì •í˜• ë°ì´í„° êµ¬ì¡° ì§€ì›
- ë‹¤ì–‘í•œ ì„œë¹„ìŠ¤ì™€ í˜¸í™˜ì„± ë†’ìŒ

**JSON ë‹¨ì **:
- ì»¬ëŸ¼ ê¸°ë°˜ ìµœì í™” ë¯¸ì§€ì›
- ë°ì´í„° í¬ê¸° ì¦ê°€ë¡œ ë¹„ìš© ìƒìŠ¹

## ğŸ” ì£¼ìš”ê°œë…

### ì»¬ëŸ¼ ê¸°ë°˜ í¬ë§· vs í–‰ ê¸°ë°˜ í¬ë§·

- **Row-based (CSV, JSON, XML)**  
  ì „ì²´ í–‰ì„ ì½ì–´ì•¼ í•˜ë¯€ë¡œ íŠ¹ì • ì»¬ëŸ¼ë§Œ í•„ìš”í•´ë„ ë¶ˆí•„ìš”í•œ ë°ì´í„°ê°€ ìŠ¤ìº”ë¨.

- **Columnar (Parquet, ORC)**  
  í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì½ê¸° ë•Œë¬¸ì— ì¿¼ë¦¬ íš¨ìœ¨ì´ ë†’ê³ , ëŒ€ê·œëª¨ ë¶„ì„ì— ìµœì .

### ì‹¤ì „ ì ìš©

- **ë¡œê·¸ ë¶„ì„**: ìˆ˜ì‹­ì–µ í–‰ì˜ CSV ë¡œê·¸ë¥¼ Parquetìœ¼ë¡œ ë³€í™˜ í›„ Athena ì¿¼ë¦¬ë¡œ ë¹ ë¥´ê²Œ ë¶„ì„  
- **BI ë¦¬í¬íŒ…**: Redshift Spectrumì—ì„œ Parquet ë°ì´í„°ë¥¼ ì§ì ‘ ì¡°íšŒí•˜ì—¬ ë¹„ìš© ì ˆê°  
- **ë°ì´í„°ë ˆì´í¬ í†µí•©**: Glue ETLë¡œ CSV â†’ Parquet ë³€í™˜ í›„ ML í•™ìŠµ/ë¶„ì„ìš© ë°ì´í„°ì„¸íŠ¸ ìƒì„±  

## ğŸ“ ê´€ë ¨ ë¬¸ì œ

**Question:**  
A Machine Learning Specialist is migrating hundreds of thousands of records in CSV files into an Amazon S3 bucket. Each file has 150 columns and is about 1 MB in size. Most of the queries will span a minimum of 5 columns. The data must be transformed to minimize the query runtime. Which transformation method will optimize query performance?

**Options:**
- A) Transform the files to JSON data format  
- B) Transform the files to gzip-compressed CSV data format  
- C) Transform the files to XML data format  
- D) Transform the files to Apache Parquet data format  

**ì •ë‹µ: D) Apache Parquet data format**

ğŸ’¡ ì¶”ê°€ ì„¤ëª…:
- **A (JSON)**: ë°˜ì •í˜• ë°ì´í„°ì—ëŠ” ìœ ìš©í•˜ì§€ë§Œ ì»¬ëŸ¼ ìµœì í™” ë¯¸ì§€ì›, ë°ì´í„° í¬ê¸° ì¦ê°€.  
- **B (gzip CSV)**: ì €ì¥ ë¹„ìš© ì ˆê°ì€ ê°€ëŠ¥í•˜ë‚˜ row-based í¬ë§·ì´ë¼ ì¿¼ë¦¬ ì„±ëŠ¥ ìµœì í™” ë¶ˆê°€.  
- **C (XML)**: Athena ì§ì ‘ ì§€ì› ë¶ˆê°€ â†’ ë¹„íš¨ìœ¨ì .  
- **D (Parquet)**: ì»¬ëŸ¼ ê¸°ë°˜, ì••ì¶• íš¨ìœ¨ì , Athena/Redshift Spectrum ìµœì í™” â†’ ê°€ì¥ ì í•©.  
