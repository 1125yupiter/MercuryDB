---

title: sagemaker-datapipeline-automation
created: 2025-08-18
modified: 2025-08-18
tags:
- service/sagemaker
- service/datapipeline
- constraint/automation
- deployment/etl
- storage/s3
aliases: ["ML Data Pipeline", "SageMaker ETL", "automated-ml-workflow"]

---

# SageMakerë¥¼ ìœ„í•œ ìë™í™”ëœ ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

## ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸

SQL Server ë°ì´í„°ë¥¼ SageMakerì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ì— ì‚¬ìš©í•˜ëŠ” ê²½ìš°, AWS Data Pipelineì„ í†µí•´ S3ë¡œ ë°ì´í„°ë¥¼ ì´ë™í•˜ì—¬ ì™„ì „ ìë™í™”ëœ ì›Œí¬í”Œë¡œë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤.

## ğŸ“ ì„¤ëª…

### AWS Data Pipelineì´ ML ì›Œí¬í”Œë¡œ ìë™í™”ì— ì í•©í•œ ì´ìœ 

AWS Data Pipelineì€ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ ê°„ì˜ ë°ì´í„° ì´ë™ê³¼ ë³€í™˜ì„ ìë™í™”í•˜ëŠ” ì›¹ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. SageMakerëŠ” ë°ì´í„° ì†ŒìŠ¤ë¡œ Amazon S3ë¥¼ ìš”êµ¬í•˜ë¯€ë¡œ, SQL Serverì—ì„œ S3ë¡œì˜ ë°ì´í„° ì´ë™ì´ í•„ìš”í•©ë‹ˆë‹¤. Data Pipelineì€ ì •ê¸°ì ì¸ ETL ì‘ì—…ì„ ìŠ¤ì¼€ì¤„ë§í•˜ê³ , ë°ì´í„° í’ˆì§ˆ ê²€ì¦, ì‹¤íŒ¨ ì²˜ë¦¬, ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•œ ê²¬ê³ í•œ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì•„í‚¤í…ì²˜ í”Œë¡œìš°

```
SQL Server (RDS) 
    â†“ (Extract)
AWS Data Pipeline
    â†“ (Transform & Load)
Amazon S3 Bucket
    â†“ (Training Data)
SageMaker Training Job
    â†“ (Model Output)
S3 Model Artifacts
    â†“ (Deployment)
SageMaker Endpoints
```

### Trade-offs ê³ ë ¤ì‚¬í•­

**AWS Data Pipeline ì¥ì **:
- ì™„ì „ ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ë¡œ ì¸í”„ë¼ ê´€ë¦¬ ë¶ˆí•„ìš”
- ìŠ¤ì¼€ì¤„ë§ ë° ì˜ì¡´ì„± ê´€ë¦¬ ìë™í™”
- ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ ëŒ€ìƒ ì§€ì›
- ì‹¤íŒ¨ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§ ë‚´ì¥
- ë¹„ìš© íš¨ìœ¨ì ì¸ ì˜¨ë””ë§¨ë“œ ì²˜ë¦¬

**AWS Data Pipeline ë‹¨ì **:
- ë³µì¡í•œ ë³€í™˜ ë¡œì§ì— ëŒ€í•œ ì œí•œ
- ì‹¤ì‹œê°„ ì²˜ë¦¬ë³´ë‹¤ëŠ” ë°°ì¹˜ ì²˜ë¦¬ì— ìµœì í™”
- ì„¤ì • ì´ˆê¸° ë³µì¡ì„±

**ì§ì ‘ ì—°ê²° ë°©ì‹ ì¥ì **:
- ì‹¤ì‹œê°„ ë°ì´í„° ì ‘ê·¼ ê°€ëŠ¥
- ì¤‘ê°„ ì €ì¥ì†Œ ì—†ì´ ì§ì ‘ ì²˜ë¦¬

**ì§ì ‘ ì—°ê²° ë°©ì‹ ë‹¨ì **:
- SageMakerì—ì„œ ì§€ì›í•˜ì§€ ì•ŠìŒ
- ë„¤íŠ¸ì›Œí¬ ì˜ì¡´ì„± ë†’ìŒ
- ë°ì´í„°ë² ì´ìŠ¤ ë¶€í•˜ ì¦ê°€

## ğŸ” ì£¼ìš”ê°œë…

### ETL vs ELT ë¹„êµ

- **ETL (Extract-Transform-Load)**: ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³  ë³€í™˜í•œ í›„ ëŒ€ìƒì— ë¡œë“œ. Data Pipelineì˜ ê¸°ë³¸ ë°©ì‹
- **ELT (Extract-Load-Transform)**: ì›ë³¸ ë°ì´í„°ë¥¼ ë¨¼ì € ë¡œë“œí•œ í›„ ëŒ€ìƒì—ì„œ ë³€í™˜. ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ì— íš¨ìœ¨ì 

### ì‹¤ì „ ì ìš©

- **ê¸ˆìœµ ì‚¬ê¸° íƒì§€**: ê±°ë˜ ë°ì´í„°ë¥¼ ë§¤ì¼ ë°¤ SQL Serverì—ì„œ S3ë¡œ ì´ë™í•˜ì—¬ ì´ìƒ íƒì§€ ëª¨ë¸ ì¬í›ˆë ¨
- **ê³ ê° ì´íƒˆ ì˜ˆì¸¡**: CRM ë°ì´í„°ë¥¼ ì£¼ê°„ ë‹¨ìœ„ë¡œ ì¶”ì¶œí•˜ì—¬ ê³ ê° í–‰ë™ íŒ¨í„´ ë¶„ì„ ëª¨ë¸ ì—…ë°ì´íŠ¸  
- **ì¬ê³  ìˆ˜ìš” ì˜ˆì¸¡**: ERP ì‹œìŠ¤í…œ ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜ì§‘í•˜ì—¬ ê³„ì ˆì„± ì˜ˆì¸¡ ëª¨ë¸ ì§€ì†ì  ê°œì„ 

## ğŸ“ ê´€ë ¨ ë¬¸ì œ

**Question:** A Machine Learning Specialist was granted access to a SQL Server hosted on Amazon RDS, whose data will be used to train a model in Amazon SageMaker. The Specialist intends to design an end-to-end solution to automate his workflow. How can the Specialist implement the solution?

**Options:**

- A) Use AWS DMS to migrate the SQL Server data to an Amazon OpenSearch cluster for quick access. Provide the cluster's endpoint within the SageMaker notebook.
- B) Directly pull the data from the SQL database by establishing a connection within the Amazon SageMaker instance.
- C) Export the Microsoft SQL Server data to Amazon DynamoDB. Provide the source DynamoDB table name within the SageMaker notebook.
- D) Use AWS Data Pipeline to copy the data from SQL Server to an S3 bucket. Provide the S3 endpoint within the SageMaker notebook.

**ì •ë‹µ: D) AWS Data Pipelineì„ ì‚¬ìš©í•˜ì—¬ SQL Serverì—ì„œ S3 ë²„í‚·ìœ¼ë¡œ ë°ì´í„° ë³µì‚¬**

ğŸ’¡ ì¶”ê°€ ì„¤ëª…:

- **ì˜µì…˜ A (AWS DMS + OpenSearch)** - OpenSearchëŠ” ê²€ìƒ‰/ë¶„ì„ìš©ìœ¼ë¡œ SageMakerì™€ ì§ì ‘ ì—°ë™ë˜ì§€ ì•Šìœ¼ë©°, ML í›ˆë ¨ì—ëŠ” S3ê°€ í•„ìš”
- **ì˜µì…˜ B (ì§ì ‘ SQL ì—°ê²°)** - SageMakerëŠ” RDS SQL Serverì™€ ì§ì ‘ ì—°ê²°ì„ ì§€ì›í•˜ì§€ ì•ŠìŒ. ë°˜ë“œì‹œ S3ë¥¼ í†µí•œ ë°ì´í„° ì œê³µ í•„ìš”
- **ì˜µì…˜ C (DynamoDB ì‚¬ìš©)** - DynamoDBë„ SageMakerì™€ ì§ì ‘ ì—°ê²° ë¶ˆê°€í•˜ë©°, ê´€ê³„í˜• ë°ì´í„°ë¥¼ NoSQLë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì€ ë¶ˆí•„ìš”í•œ ë³µì¡ì„± ì¶”ê°€