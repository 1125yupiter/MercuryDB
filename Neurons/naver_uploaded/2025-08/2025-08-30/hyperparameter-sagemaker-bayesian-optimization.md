---

title: hyperparameter-sagemaker-bayesian-optimization
created: 2025-08-20
modified: 2025-08-20
tags:
- service/sagemaker
- technique/hyperparameter-tuning
- method/bayesian-optimization
- optimization/automatic
- tuning/intelligent
aliases: ["HPO", "hyperparameter-optimization", "bayesian-tuning"]

---

# Amazon SageMaker ν•μ΄νΌνλΌλ―Έν„° νλ‹ - λ² μ΄μ§€μ• μµμ ν™” κΈ°λ° μλ™ νλ‹

## π― ν•µμ‹¬ ν¬μΈνΈ

λ¨Έμ‹ λ¬λ‹ λ¨λΈμ μ„±λ¥μ„ μµμ ν™”ν•΄μ•Ό ν•λ” κ²½μ° Amazon SageMakerμ—μ„, λ² μ΄μ§€μ• μµμ ν™” κΈ°λ°μ μλ™ ν•μ΄νΌνλΌλ―Έν„° νλ‹μ„ ν†µν•΄ ν¨μ¨μ μΌλ΅ μµμ μ νλΌλ―Έν„° μ΅°ν•©μ„ μ°Ύμ„ μ μλ‹¤.

## π“ μ„¤λ…

### Amazon SageMakerκ°€ ν•μ΄νΌνλΌλ―Έν„° νλ‹μ— μ ν•©ν• μ΄μ 

Amazon SageMakerλ” λ² μ΄μ§€μ• μµμ ν™”(Bayesian Optimization)λ¥Ό ν•µμ‹¬ μ—”μ§„μΌλ΅ μ‚¬μ©ν•μ—¬ μλ™ ν•μ΄νΌνλΌλ―Έν„° νλ‹μ„ μ κ³µν•©λ‹λ‹¤. μ΄ λ°©μ‹μ€ μ΄μ „ μ‹¤ν— κ²°κ³Όλ¥Ό ν•™μµν•μ—¬ λ‹¤μμ— μ‹λ„ν•  μµμ μ ν•μ΄νΌνλΌλ―Έν„° μ΅°ν•©μ„ μ§€λ¥μ μΌλ΅ μμΈ΅ν•λ―€λ΅, λ¬΄μ‘μ„ κ²€μƒ‰μ΄λ‚ κ·Έλ¦¬λ“ κ²€μƒ‰λ³΄λ‹¤ ν›¨μ”¬ ν¨μ¨μ μ…λ‹λ‹¤. λ‚΄μ¥ μ•κ³ λ¦¬μ¦λΏλ§ μ•„λ‹λΌ μ‚¬μ©μ μ •μ μ•κ³ λ¦¬μ¦μ—μ„λ„ λ™μΌν•κ² μ μ©ν•  μ μμ–΄ λ²”μ©μ„±μ΄ λ›°μ–΄λ‚©λ‹λ‹¤.

### μ•„ν‚¤ν…μ² ν”λ΅μ°

```
μ΄κΈ° μ‹¤ν— (Random Sampling)
    β†“
ν•μ΄νΌνλΌλ―Έν„° μ΅°ν•© A, B, C ν…μ¤νΈ
    β†“
μ„±λ¥ κ²°κ³Ό μμ§‘ λ° λ¶„μ„
    β†“
λ² μ΄μ§€μ• μµμ ν™” λ¨λΈ ν•™μµ
    β†“
λ‹¤μ μµμ  μ΅°ν•© μμΈ΅ λ° μ„ νƒ
    β†“
μƒλ΅μ΄ μ‹¤ν— μ‹¤ν–‰
    β†“
κ²°κ³Ό ν”Όλ“λ°± β†’ λ¨λΈ μ—…λ°μ΄νΈ
    β†“
μλ ΄κΉμ§€ λ°λ³µ
```

### Trade-offs κ³ λ ¤μ‚¬ν•­

**λ² μ΄μ§€μ• μµμ ν™” μ¥μ **:
- μ΄μ „ μ‹¤ν— κ²°κ³Όλ¥Ό ν™μ©ν• μ§€λ¥μ  νƒμƒ‰
- μ μ€ μ‹¤ν— νμλ΅ μµμ κ°’ λ°κ²¬ κ°€λ¥
- μ‹κ°„κ³Ό λΉ„μ© ν¨μ¨μ„±μ΄ λ›°μ–΄λ‚¨
- λ³µμ΅ν• νλΌλ―Έν„° κ³µκ°„μ—μ„λ„ ν¨κ³Όμ 

**λ² μ΄μ§€μ• μµμ ν™” λ‹¨μ **:
- μ΄κΈ° λ‡ λ²μ μ‹¤ν—μ€ λλ¤ν•κ² μ§„ν–‰
- λ§¤μ° κ°„λ‹¨ν• κ²½μ° κ·Έλ¦¬λ“ κ²€μƒ‰μ΄ λ” μ§κ΄€μ μΌ μ μμ

**κ·Έλ¦¬λ“ κ²€μƒ‰ μ¥μ **:
- λ¨λ“  μ΅°ν•©μ„ μ²΄κ³„μ μΌλ΅ νƒμƒ‰
- κ²°κ³Όκ°€ μ™„μ „ν μμΈ΅ κ°€λ¥

**κ·Έλ¦¬λ“ κ²€μƒ‰ λ‹¨μ **:
- νλΌλ―Έν„° μκ°€ μ¦κ°€ν•λ©΄ μ§€μμ μΌλ΅ μ‹¤ν— μ μ¦κ°€
- μ‹κ°„κ³Ό λΉ„μ©μ΄ λ§¤μ° λ§μ΄ μ†μ”λ¨
- λΉ„ν¨μ¨μ μΈ νƒμƒ‰

**λλ¤ κ²€μƒ‰ μ¥μ **:
- κµ¬ν„μ΄ κ°„λ‹¨ν•¨
- κ·Έλ¦¬λ“ κ²€μƒ‰λ³΄λ‹¤λ” ν¨μ¨μ 

**λλ¤ κ²€μƒ‰ λ‹¨μ **:
- μ΄μ „ κ²°κ³Όλ¥Ό ν™μ©ν•μ§€ λ»ν•¨
- μ—¬μ „ν λ§μ€ μ‹¤ν—μ΄ ν•„μ”

## π” μ£Όμ”κ°λ…

### ν•μ΄νΌνλΌλ―Έν„° νλ‹ λ°©λ²•λ΅  λΉ„κµ

- **κ·Έλ¦¬λ“ κ²€μƒ‰ (Grid Search)**: μ‚¬μ „ μ •μλ λ¨λ“  νλΌλ―Έν„° μ΅°ν•©μ„ μ²΄κ³„μ μΌλ΅ ν…μ¤νΈν•λ” λ°©λ²•. μ™„μ „ν•μ§€λ§ λ§¤μ° λΉ„ν¨μ¨μ 
- **λλ¤ κ²€μƒ‰ (Random Search)**: νλΌλ―Έν„° κ³µκ°„μ—μ„ λ¬΄μ‘μ„λ΅ μ΅°ν•©μ„ μ„ νƒν•μ—¬ ν…μ¤νΈ. κ·Έλ¦¬λ“ κ²€μƒ‰λ³΄λ‹¤ λΉ λ¥΄μ§€λ§ μ—¬μ „ν λΉ„ν¨μ¨μ 
- **λ² μ΄μ§€μ• μµμ ν™” (Bayesian Optimization)**: μ΄μ „ μ‹¤ν— κ²°κ³Όλ¥Ό λ°”νƒ•μΌλ΅ κ°€μ¥ μ λ§ν• λ‹¤μ μ΅°ν•©μ„ μμΈ΅ν•μ—¬ ν…μ¤νΈ. κ°€μ¥ ν¨μ¨μ μΈ λ°©λ²•

### μ‹¤μ „ μ μ©

- **μ΄λ―Έμ§€ λ¶„λ¥ λ¨λΈ**: learning rate, batch size, hidden layer μ λ“±μ„ μλ™μΌλ΅ νλ‹ν•μ—¬ μ •ν™•λ„ ν–¥μƒ
- **μ‹κ³„μ—΄ μμΈ΅**: DeepAR λ¨λΈμ context length, prediction length, embedding dimension μµμ ν™”
- **μμ—°μ–΄ μ²λ¦¬**: BERT λ¨λΈμ learning rate, warmup steps, dropout rate λ“±μ„ ν¨μ¨μ μΌλ΅ νƒμƒ‰

## π“ κ΄€λ ¨ λ¬Έμ 

**Question:** A data scientist needs to optimize hyperparameters for a custom machine learning algorithm deployed on Amazon SageMaker. The algorithm has 5 hyperparameters with continuous ranges, and the scientist wants to minimize training time while finding optimal values. Which approach should be used?

**Options:**

- A) Grid search across all possible parameter combinations
- B) Random search with 1000 random parameter combinations
- C) SageMaker automatic hyperparameter tuning with Bayesian optimization
- D) Manual tuning based on domain expertise
- E) Sequential search testing one parameter at a time

**μ •λ‹µ: C) SageMaker automatic hyperparameter tuning with Bayesian optimization**

π’΅ μ¶”κ°€ μ„¤λ…:

- **Option A (Grid Search)** - 5κ° μ—°μ†ν• νλΌλ―Έν„°μ— λ€ν•΄ κ·Έλ¦¬λ“ κ²€μƒ‰μ€ μ‹¤μ§μ μΌλ΅ λ¶κ°€λ¥ν•λ©° λ§¤μ° λΉ„ν¨μ¨μ 
- **Option B (Random Search)** - 1000λ²μ λ¬΄μ‘μ„ μ‹λ„λ” μ΄μ „ κ²°κ³Όλ¥Ό ν™μ©ν•μ§€ λ»ν•΄ λΉ„ν¨μ¨μ 
- **Option D (Manual Tuning)** - λ„λ©”μΈ μ „λ¬Έμ„±μ— μμ΅΄ν•λ©° κ°κ΄€μ μ΄μ§€ μ•κ³  ν™•μ¥μ„±μ΄ λ–¨μ–΄μ§
- **Option E (Sequential Search)** - νλΌλ―Έν„° κ°„ μƒνΈμ‘μ©μ„ κ³ λ ¤ν•μ§€ λ»ν•κ³  λ§¤μ° λλ¦Ό