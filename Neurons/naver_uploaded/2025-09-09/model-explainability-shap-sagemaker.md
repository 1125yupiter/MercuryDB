---

title: model-explainability-shap-sagemaker
created: 2025-08-26
modified: 2025-08-26
tags:
- service/sagemaker
- technique/shap
- constraint/interpretability
- usecase/credit-scoring
- compliance/regulatory
aliases: ["model-interpretability", "SHAP", "explainability"]

---

# ëª¨ë¸ í•´ì„ ê°€ëŠ¥ì„±: SHAPì™€ SageMaker Model Monitorë¥¼ í™œìš©í•œ ì‹ ìš© ê²°ì • ì„¤ëª…

## ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸

ê°œë³„ ê³ ê°ì˜ ì‹ ìš© ê²°ì •ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì„¤ëª…ì´ í•„ìš”í•œ ê²½ìš° SageMaker Model Monitorì—ì„œ, SHAP ê°’ì„ í™œìš©í•˜ì—¬ ê° í”¼ì²˜ê°€ íŠ¹ì • ì˜ˆì¸¡ì— ë¯¸ì¹œ ì˜í–¥ì„ ë¶„ì„í•  ìˆ˜ ìˆë‹¤.

## ğŸ“ ì„¤ëª…

### SHAPê°€ ì‹ ìš© ê²°ì • ì„¤ëª…ì— ì í•©í•œ ì´ìœ 

SHAP(SHapley Additive exPlanations)ëŠ” ê²Œì„ ì´ë¡ ì˜ Shapley ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ê°œë³„ ì˜ˆì¸¡ì— ëŒ€í•œ ê° í”¼ì²˜ì˜ ê¸°ì—¬ë„ë¥¼ ì •í™•íˆ ê³„ì‚°í•©ë‹ˆë‹¤. ì‹ ìš© ì‹¬ì‚¬ì™€ ê°™ì´ ê·œì œ ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ ì¸í•´ ê°œë³„ ê²°ì •ì— ëŒ€í•œ ëª…í™•í•œ ì„¤ëª…ì´ í•„ìš”í•œ ê²½ìš°, ì „ì—­ì  í”¼ì²˜ ì¤‘ìš”ë„ì™€ ë‹¬ë¦¬ "ì™œ ì´ íŠ¹ì • ê³ ê°ì´ ê±°ë¶€ë˜ì—ˆëŠ”ê°€?"ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

SageMaker Model MonitorëŠ” ë°°í¬ëœ ëª¨ë¸ì˜ ì‹¤ì‹œê°„ ì¶”ë¡  ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ê³  ì €ì¥í•˜ì—¬, ì´í›„ SHAP ë¶„ì„ì˜ ì›ì¬ë£Œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì§€ì†ì ì¸ ëª¨ë¸ í•´ì„ê³¼ ê·œì œ ì¤€ìˆ˜ë¥¼ ë™ì‹œì— ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì•„í‚¤í…ì²˜ í”Œë¡œìš°

```
Historical Data â†’ XGBoost Training (SageMaker) â†’ Model Deployment (Endpoint)
                                                      â†“
Customer Request â†’ Real-time Inference â†’ Model Monitor (Data Collection)
                                                      â†“
Inference Data â†’ SHAP Analysis â†’ Feature Contribution Chart â†’ Credit Team
```

### Trade-offs ê³ ë ¤ì‚¬í•­

**SHAP ì¥ì **:
- ê°œë³„ ì˜ˆì¸¡ì— ëŒ€í•œ ì •í™•í•œ ì„¤ëª… ì œê³µ
- ê·œì œ ìš”êµ¬ì‚¬í•­ ë§Œì¡± (Fair Credit Reporting Act ë“±)
- ê²Œì„ ì´ë¡  ê¸°ë°˜ì˜ ìˆ˜í•™ì ìœ¼ë¡œ ì—„ë°€í•œ ë°©ë²•ë¡ 
- í”¼ì²˜ë³„ ê¸°ì—¬ë„ì˜ í•©ì´ ì˜ˆì¸¡ê°’ê³¼ ê¸°ì¤€ê°’ì˜ ì°¨ì´ì™€ ì¼ì¹˜

**SHAP ë‹¨ì **:
- ê³„ì‚° ë¹„ìš©ì´ ë†’ìŒ (íŠ¹íˆ ë³µì¡í•œ ëª¨ë¸)
- ì‹¤ì‹œê°„ ì„¤ëª… ìƒì„± ì‹œ ë ˆì´í„´ì‹œ ì¦ê°€ ê°€ëŠ¥
- ë¹„ì „ë¬¸ê°€ì—ê²ŒëŠ” í•´ì„ì´ ì—¬ì „íˆ ë³µì¡í•  ìˆ˜ ìˆìŒ

**Feature Importance ì¥ì **:
- ë¹ ë¥¸ ê³„ì‚° ì†ë„
- ì „ì²´ ëª¨ë¸ì— ëŒ€í•œ ì§ê´€ì  ì´í•´
- êµ¬í˜„ì´ ê°„ë‹¨í•¨

**Feature Importance ë‹¨ì **:
- ê°œë³„ ì˜ˆì¸¡ì— ëŒ€í•œ ì„¤ëª… ë¶ˆê°€
- "ì™œ ì´ ê³ ê°ì´ ê±°ë¶€ë˜ì—ˆëŠ”ê°€?"ì— ëŒ€í•œ ë‹µë³€ ì œê³µ ë¶ˆê°€
- ê·œì œ ìš”êµ¬ì‚¬í•­ ë¯¸ì¶©ì¡±

## ğŸ” ì£¼ìš”ê°œë…

### í•´ì„ ê°€ëŠ¥ì„± ë°©ë²•ë¡  ë¹„êµ

- **SHAP (Local Explainability)**: ê°œë³„ ì˜ˆì¸¡ì˜ ê° í”¼ì²˜ë³„ ê¸°ì—¬ë„ë¥¼ ì •í™•íˆ ê³„ì‚°. "ê¹€ì² ìˆ˜ ê³ ê°ì˜ ê²½ìš° ë‚˜ì´(+0.3), ì†Œë“(-0.7), ì‹ ìš©ì ìˆ˜(+0.5)ê°€ ìµœì¢… ê²°ì •ì— ì˜í–¥"
- **Feature Importance (Global Explainability)**: ëª¨ë¸ ì „ì²´ì—ì„œ ê° í”¼ì²˜ì˜ ì¼ë°˜ì  ì¤‘ìš”ë„. "ì „ì²´ì ìœ¼ë¡œ ì†Œë“ì´ ê°€ì¥ ì¤‘ìš”í•œ í”¼ì²˜ì´ê³ , ë‚˜ì´, ì‹ ìš©ì ìˆ˜ ìˆœ"

### ì‹¤ì „ ì ìš©

- **ì‹ ìš©ì¹´ë“œ ë°œê¸‰ ê±°ë¶€ ì‹œ**: SHAPë¡œ êµ¬ì²´ì  ê±°ë¶€ ì‚¬ìœ ë¥¼ ê³ ê°ì—ê²Œ ì„¤ëª…
- **ëŒ€ì¶œ ì‹¬ì‚¬ íˆ¬ëª…ì„±**: ê° ê³ ê°ë³„ ë§ì¶¤í˜• ë¦¬ìŠ¤í¬ ìš”ì¸ ë¶„ì„ ì œê³µ
- **ê·œì œ ê°ì‚¬ ëŒ€ì‘**: ê°œë³„ ê²°ì •ì— ëŒ€í•œ ê°ê´€ì ì´ê³  ìˆ˜í•™ì ì¸ ê·¼ê±° ì œì‹œ

## ğŸ“ ê´€ë ¨ ë¬¸ì œ

**Question:** A bank wants to introduce a low-interest credit campaign targeting specific customers affected by economic difficulties. The credit team uses an XGBoost model with sufficient accuracy but struggles to explain why certain customers are rejected for credit. The team has little data science expertise and needs to understand individual credit decisions for regulatory compliance. What should the data science team implement to address this explainability challenge most effectively?

**Options:**

- A) Use Amazon SageMaker Studio with XGBoost training container, deploy model at endpoint, enable SageMaker Model Monitor to store inferences, and create SHAP values to generate feature contribution charts
- B) Use Amazon SageMaker Studio with XGBoost training container, activate SageMaker Debugger to calculate Shapley values during training
- C) Create SageMaker notebook instance, retrain model locally with XGBoost library, use plot_importance() method to create feature importance charts
- D) Use SageMaker Studio with XGBoost training container, deploy model, use SageMaker Processing to automatically create feature importance explainability charts

**ì •ë‹µ: A) SageMaker Model Monitor + SHAP**

ğŸ’¡ ì¶”ê°€ ì„¤ëª…:

- **Option B (SageMaker Debugger)** - í›ˆë ¨ ì¤‘ ë””ë²„ê¹… ë„êµ¬ë¡œ, ë°°í¬ í›„ ê°œë³„ ì¶”ë¡  ì„¤ëª…ê³¼ëŠ” ë¬´ê´€í•¨
- **Option C (plot_importance())** - ì „ì—­ì  í”¼ì²˜ ì¤‘ìš”ë„ë§Œ ì œê³µí•˜ì—¬ ê°œë³„ ê³ ê°ë³„ ê²°ì • ì„¤ëª… ë¶ˆê°€
- **Option D (SageMaker Processing)** - Feature importance ê¸°ë°˜ìœ¼ë¡œ "ì™œ ì´ íŠ¹ì • ê³ ê°ì´ ê±°ë¶€ë˜ì—ˆë‚˜?"ì— ë‹µë³€ ë¶ˆê°€

---