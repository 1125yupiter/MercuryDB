---

title: ml-deployment-sagemaker-realtime
created: 2025-08-21
modified: 2025-08-21
tags:
- service/sagemaker
- constraint/real-time
- deployment/hosting
- performance/low-latency
- architecture/high-availability
aliases: ["SageMaker Hosting", "ML Real-time Deployment", "AWS ML Inference"]

---

# Amazon SageMakerë¥¼ ì´ìš©í•œ ML ëª¨ë¸ ì‹¤ì‹œê°„ ë°°í¬

## ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸

SageMaker íŒŒì´í”„ë¼ì¸ì—ì„œ í›ˆë ¨ëœ ëª¨ë¸ì„ ì‹¤ì‹œê°„ ì¶”ë¡ ì— ë°°í¬í•˜ëŠ” ê²½ìš°, SageMaker Hosting Services with Auto Scalingì—ì„œ ì €ì§€ì—°ê³¼ ê³ ê°€ìš©ì„±ì„ ë™ì‹œì— í™•ë³´í•  ìˆ˜ ìˆë‹¤.

## ğŸ“ ì„¤ëª…

### SageMaker Hosting Servicesê°€ ì‹¤ì‹œê°„ ML ì¶”ë¡ ì— ì í•©í•œ ì´ìœ 

SageMaker Hosting ServicesëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ì‹¤ì‹œê°„ ì¶”ë¡ ì„ ìœ„í•´ íŠ¹ë³„íˆ ì„¤ê³„ëœ ì™„ì „ ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. ê¸°ìˆ ì ìœ¼ë¡œëŠ” Model ê°ì²´, Endpoint Configuration, ê·¸ë¦¬ê³  ì‹¤ì œ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ëŠ” SageMaker Endpointë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ì´ ì„œë¹„ìŠ¤ëŠ” ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ê´€ë¦¬í•˜ê³ , ë‹¤ì–‘í•œ ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…ì„ ì§€ì›í•˜ë©°, íŠ¸ë˜í”½ íŒ¨í„´ì— ë”°ë¥¸ ìë™ ìŠ¤ì¼€ì¼ë§ì„ ì œê³µí•©ë‹ˆë‹¤. íŠ¹íˆ SageMaker íŒŒì´í”„ë¼ì¸ê³¼ì˜ ì™„ë²½í•œ í†µí•©ì„ í†µí•´ ëª¨ë¸ í›ˆë ¨ë¶€í„° ë°°í¬ê¹Œì§€ì˜ ì „ì²´ MLOps ì›Œí¬í”Œë¡œìš°ë¥¼ ì¼ê´€ë˜ê²Œ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì•„í‚¤í…ì²˜ í”Œë¡œìš°

```
SageMaker Hosting Services ë°°í¬ ê³¼ì •:
Model â†’ Endpoint Configuration â†’ Endpoint (ì‹¤ì œ ì¸ìŠ¤í„´ìŠ¤)

ì‚¬ìš©ì ìš”ì²­ â†’ Application Load Balancer â†’ 
â”œâ”€ SageMaker Endpoint Instance (AZ-1a) âœ…
â”œâ”€ SageMaker Endpoint Instance (AZ-1b) âœ…  
â””â”€ SageMaker Endpoint Instance (AZ-1c) âœ…
          â†“
    Auto Scaling Group
    (íŠ¸ë˜í”½ ê¸°ë°˜ ìë™ ì¡°ì •)
          â†“
    CloudWatch ëª¨ë‹ˆí„°ë§
```

### ê¸°ìˆ ì  êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

**ì‹¤ì œ ë°°í¬ ê³¼ì •:**
```python
# 1. Model ìƒì„± (S3 ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì°¸ì¡°)
model = sagemaker.Model(image_uri, model_data, role)

# 2. Endpoint Configuration ìƒì„±
endpoint_config = model.create_endpoint_config(
    instance_type='ml.m5.xlarge', 
    initial_instance_count=2
)

# 3. ì‹¤ì œ Endpoint ë°°í¬ (ì´ê²ƒì´ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ëŠ” ì¸ìŠ¤í„´ìŠ¤)
predictor = model.deploy(endpoint_name='my-model-endpoint')
```

**ì¶”ë¡  í˜¸ì¶œ:**
```python
# ì§ì ‘ Endpoint ì´ë¦„ìœ¼ë¡œ í˜¸ì¶œ
response = sagemaker_runtime.invoke_endpoint(
    EndpointName='my-model-endpoint',
    Body=json.dumps(data)
)
```

### Trade-offs ê³ ë ¤ì‚¬í•­

**SageMaker Hosting Services ì¥ì **:
- ML ì¶”ë¡ ì— ìµœì í™”ëœ ì¸í”„ë¼ì™€ ì„±ëŠ¥
- Multi-AZ ë°°í¬ë¥¼ í†µí•œ ê³ ê°€ìš©ì„± ë³´ì¥
- ìë™ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ íŠ¸ë˜í”½ ë³€í™”ì— ëŒ€ì‘
- SageMaker ìƒíƒœê³„ì™€ì˜ ì™„ë²½í•œ í†µí•©
- A/B í…ŒìŠ¤íŒ… ë° ì¹´ë‚˜ë¦¬ ë°°í¬ ì§€ì›
- GPU ì¸ìŠ¤í„´ìŠ¤ ë“± ë‹¤ì–‘í•œ ì»´í“¨íŒ… ì˜µì…˜

**SageMaker Hosting Services ë‹¨ì **:
- ì§€ì†ì ì¸ ì¸ìŠ¤í„´ìŠ¤ ìš´ì˜ìœ¼ë¡œ ì¸í•œ ê³ ì • ë¹„ìš©
- ì„œë²„ë¦¬ìŠ¤ ëŒ€ë¹„ ê´€ë¦¬ ë³µì¡ì„± ì¡´ì¬

**Lambda + Provisioned Concurrency ì¥ì **:
- Cold start ì œê±°ë¡œ ì¼ê´€ëœ ì‘ë‹µ ì‹œê°„
- ì„œë²„ë¦¬ìŠ¤ ì•„í‚¤í…ì²˜ì˜ ìë™ í™•ì¥ì„±
- ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ì™€ì˜ ìì—°ìŠ¤ëŸ¬ìš´ í†µí•©

**Lambda + Provisioned Concurrency ë‹¨ì **:
- ë©”ëª¨ë¦¬ ì œí•œ (ìµœëŒ€ 10GB)ìœ¼ë¡œ ëŒ€ìš©ëŸ‰ ëª¨ë¸ ì²˜ë¦¬ ì–´ë ¤ì›€
- ì‹¤í–‰ ì‹œê°„ ì œí•œ (15ë¶„)ìœ¼ë¡œ ë³µì¡í•œ ì¶”ë¡  ë¶ˆê°€
- GPU ì§€ì› ë¶€ì¬ë¡œ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì„±ëŠ¥ ì œì•½
- SageMaker íŒŒì´í”„ë¼ì¸ê³¼ì˜ ë¶ˆì™„ì „í•œ í†µí•©

## ğŸ” ì£¼ìš”ê°œë…

### í•µì‹¬ ë°°í¬ ì˜µì…˜ ë¹„êµ

- **SageMaker Hosting Services**: Model â†’ EndpointConfig â†’ Endpointë¡œ êµ¬ì„±ë˜ëŠ” ì „ìš© ì¸ìŠ¤í„´ìŠ¤ ê¸°ë°˜ ì‹¤ì‹œê°„ ì¶”ë¡  ì„œë¹„ìŠ¤
- **SageMaker Endpoint**: ì‹¤ì œ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ëŠ” ë°°í¬ëœ ì¸ìŠ¤í„´ìŠ¤ (Hosting Servicesì˜ í•µì‹¬ êµ¬ì„±ìš”ì†Œ)
- **Lambda**: ì„œë²„ë¦¬ìŠ¤ ì»´í“¨íŒ… ì„œë¹„ìŠ¤ë¡œ ì´ë²¤íŠ¸ ê¸°ë°˜ ì‹¤í–‰ì— ìµœì í™”
- **EKS**: ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í”Œë«í¼ìœ¼ë¡œ ë³µì¡í•œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ì— ì í•©
- **API Gateway**: API ê´€ë¦¬ ì„œë¹„ìŠ¤ë¡œ ì‹¤ì œ ì¶”ë¡  ì¸í”„ë¼ëŠ” ë³„ë„ í•„ìš”

### ìš©ì–´ ì •ë¦¬

- **"SageMaker í˜¸ìŠ¤íŒ…ìœ¼ë¡œ ë°°í¬"** = ë¹„ì¦ˆë‹ˆìŠ¤/ì„œë¹„ìŠ¤ ë ˆë²¨ í‘œí˜„ (ì „ì²´ ì„œë¹„ìŠ¤ ì‚¬ìš©)
- **"SageMaker ì—”ë“œí¬ì¸íŠ¸ ìƒì„±"** = ê¸°ìˆ ì /êµ¬í˜„ ë ˆë²¨ í‘œí˜„ (ì‹¤ì œ AWS ë¦¬ì†ŒìŠ¤)

### ì‹¤ì „ ì ìš©

- **ê³ ë¹ˆë„ ê±°ë˜ ì‹œìŠ¤í…œ**: ê¸ˆìœµ ì‚¬ê¸° íƒì§€ ëª¨ë¸ì˜ ì‹¤ì‹œê°„ ì¶”ë¡  (ë°€ë¦¬ì´ˆ ë‹¨ìœ„ ì‘ë‹µ í•„ìš”)
- **ê°œì¸í™” ì¶”ì²œ ì—”ì§„**: ì „ììƒê±°ë˜ ì‚¬ì´íŠ¸ì˜ ì‹¤ì‹œê°„ ìƒí’ˆ ì¶”ì²œ (ì§€ì†ì  íŠ¸ë˜í”½)
- **ì˜ë£Œ ì§„ë‹¨ ì§€ì›**: ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ì„ì„ ìœ„í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì„œë¹™ (GPU ê°€ì† í•„ìš”)

## ğŸ“ ê´€ë ¨ ë¬¸ì œ

**Question:** You are building a machine learning pipeline using Amazon SageMaker and need to deploy a trained model for real-time inference with high availability and low latency. Which of the following deployment options would be the best fit for your use case?

**Options:**

- A) AWS Lambda with Provisioned Concurrency
- B) Amazon API Gateway
- C) Amazon Elastic Kubernetes Service (EKS)
- D) Amazon SageMaker Hosting Services with Auto Scaling
- E) Amazon EC2 with Application Load Balancer

**ì •ë‹µ: D) Amazon SageMaker Hosting Services with Auto Scaling**

ğŸ’¡ ì¶”ê°€ ì„¤ëª…:

- **AWS Lambda** - ë©”ëª¨ë¦¬ ë° ì‹¤í–‰ ì‹œê°„ ì œí•œìœ¼ë¡œ ë³µì¡í•œ ML ëª¨ë¸ ì²˜ë¦¬ì— ë¶€ì í•©, SageMaker íŒŒì´í”„ë¼ì¸ê³¼ì˜ í†µí•© ë³µì¡ì„±
- **Amazon API Gateway** - API ê´€ë¦¬ ì„œë¹„ìŠ¤ì¼ ë¿ ì‹¤ì œ ì¶”ë¡ ì„ ìœ„í•œ ì»´í“¨íŒ… ì¸í”„ë¼ ë¯¸ì œê³µ
- **Amazon EKS** - ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë³µì¡ì„±, ML ì¶”ë¡ ì— íŠ¹í™”ë˜ì§€ ì•Šì€ ë²”ìš© í”Œë«í¼
- **Amazon EC2** - ì¸í”„ë¼ ê´€ë¦¬ ë¶€ë‹´, SageMaker ìƒíƒœê³„ ì´ì  í™œìš© ë¶ˆê°€