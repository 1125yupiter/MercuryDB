---

title: sagemaker-ntm-stopwords-preprocessing
created: 2025-08-26
modified: 2025-08-26
tags:
- service/sagemaker
- algorithm/ntm
- preprocessing/countvectorizer
- problem/stopwords
- technique/text-cleaning
aliases: ["NTM", "Neural Topic Model", "CountVectorizer", "stopwords"]

---

# SageMaker NTMì—ì„œ ë¶ˆìš©ì–´ ì œê±°ë¥¼ í†µí•œ íƒœê·¸ í’ˆì§ˆ ê°œì„ 

## ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸

ë¸”ë¡œê·¸ íƒœê·¸ ì¶”ì²œ ëª¨ë¸ì—ì„œ ë¶ˆìš©ì–´ê°€ íƒœê·¸ë¡œ ì œì•ˆë˜ëŠ” ê²½ìš°, CountVectorizerë¥¼ í†µí•´ ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ë¶ˆìš©ì–´ë¥¼ ì™„ì „íˆ ì œê±°í•˜ì—¬ ì •ì œëœ ë°ì´í„°ë¡œ NTMì„ ì¬í›ˆë ¨í•  ìˆ˜ ìˆë‹¤.

## ğŸ“ ì„¤ëª…

### CountVectorizerê°€ NTM ì „ì²˜ë¦¬ì— ì í•©í•œ ì´ìœ 

CountVectorizerëŠ” í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì—ì„œ `stop_words` ë§¤ê°œë³€ìˆ˜ë¥¼ í†µí•´ ë¶ˆìš©ì–´ë¥¼ ì›ì²œ ì°¨ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ í•™ìŠµí•˜ê¸° ì „ì— ë°ì´í„° ìì²´ì—ì„œ ë¶ˆìš©ì–´ë¥¼ ì™„ì „íˆ ì œê±°í•˜ë¯€ë¡œ, NTMì´ ë¶ˆìš©ì–´ë¥¼ íƒœê·¸ í›„ë³´ë¡œ í•™ìŠµí•  ê°€ëŠ¥ì„±ì„ ì›ì²œ ë´‰ì‡„í•©ë‹ˆë‹¤.

í•µì‹¬ì€ **ì‚¬í›„ í•„í„°ë§ì´ ì•„ë‹Œ ì‚¬ì „ ë°ì´í„° ì •ì œ** ì ‘ê·¼ë²•ì…ë‹ˆë‹¤. ë¶ˆìš©ì–´ê°€ ì œê±°ëœ ê¹¨ë—í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ ëª¨ë¸ì„ ì¬í›ˆë ¨í•˜ë©´, ì• ì´ˆì— ë¶ˆìš©ì–´ê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í•™ìŠµ í™˜ê²½ì´ êµ¬ì„±ë©ë‹ˆë‹¤.

### ì•„í‚¤í…ì²˜ í”Œë¡œìš°

```
Raw Blog Data (S3) 
    â†“
CountVectorizer ì „ì²˜ë¦¬
- stop_words='english' ì„¤ì •
- ë¶ˆìš©ì–´ ì™„ì „ ì œê±°
- í¬ê·€ ë‹¨ì–´ ë³´ì¡´ (min_df, max_df ì¡°ì •)
    â†“
ì •ì œëœ í…ìŠ¤íŠ¸ ë°ì´í„° (S3)
    â†“
SageMaker NTM ì¬í›ˆë ¨
    â†“
ë¶ˆìš©ì–´ ì—†ëŠ” íƒœê·¸ ì¶”ì²œ ëª¨ë¸
```

### Trade-offs ê³ ë ¤ì‚¬í•­

**CountVectorizer ì¥ì **:
- ë¶ˆìš©ì–´ ì›ì²œ ì°¨ë‹¨ìœ¼ë¡œ ê·¼ë³¸ì  í•´ê²°
- í¬ê·€ ë‹¨ì–´ ë³´ì¡´ ê°€ëŠ¥ (min_df, max_df í™œìš©)
- scikit-learn í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ì•ˆì •ì„± ë³´ì¥
- ê¸°ì¡´ NTM ì›Œí¬í”Œë¡œìš° ìœ ì§€ ê°€ëŠ¥

**CountVectorizer ë‹¨ì **:
- ì „ì²´ ë°ì´í„° ì¬ì²˜ë¦¬ í•„ìš”
- S3 ë°ì´í„° êµì²´ë¡œ ì¸í•œ ìŠ¤í† ë¦¬ì§€ ë¹„ìš©
- ì´ˆê¸° ì„¤ì • ì‹œ ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ì»¤ìŠ¤í„°ë§ˆì´ì§• í•„ìš”

**Amazon Comprehend ì¥ì **:
- ê³ ê¸‰ NLP ê¸°ëŠ¥ ì œê³µ

**Amazon Comprehend ë‹¨ì **:
- ê°œì²´ ì¸ì‹ ê¸°ëŠ¥ìœ¼ë¡œ ë¶ˆìš©ì–´ ì œê±°ì™€ ì§ì ‘ì  ê´€ë ¨ ì—†ìŒ
- ì¶”ê°€ API í˜¸ì¶œ ë¹„ìš© ë°œìƒ

**PCA ì¥ì **:
- ì°¨ì› ì¶•ì†Œë¥¼ í†µí•œ ê³„ì‚° íš¨ìœ¨ì„±

**PCA ë‹¨ì **:
- í† í”½ ëª¨ë¸ë§ê³¼ ë¬´ê´€í•œ ê¸°ë²•
- ë¶ˆìš©ì–´ ë¬¸ì œ í•´ê²° ë¶ˆê°€

**Object Detection ì¥ì **:
- ì´ë¯¸ì§€ ì²˜ë¦¬ì— íŠ¹í™”

**Object Detection ë‹¨ì **:
- í…ìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬ì™€ ì™„ì „íˆ ë¬´ê´€
- ë¬¸ì œ ìƒí™©ê³¼ ì „í˜€ ë§ì§€ ì•ŠìŒ

## ğŸ” ì£¼ìš”ê°œë…

### ì „ì²˜ë¦¬ ë°©ì‹ ë¹„êµ

- **ì‚¬ì „ ë°ì´í„° ì •ì œ**: CountVectorizerë¡œ ë¶ˆìš©ì–´ë¥¼ ì™„ì „íˆ ì œê±°í•œ í›„ ëª¨ë¸ í•™ìŠµ
- **ì‚¬í›„ ê²°ê³¼ í•„í„°ë§**: ëª¨ë¸ ê²°ê³¼ì—ì„œ ë¶ˆìš©ì–´ íƒœê·¸ë§Œ ì œê±° (ê·¼ë³¸ì  í•´ê²° ì•„ë‹˜)

### ì‹¤ì „ ì ìš©

- **ë¸”ë¡œê·¸ íƒœê·¸ ì‹œìŠ¤í…œ**: ê¸°ìˆ  ë¸”ë¡œê·¸ì—ì„œ "the", "and" ê°™ì€ ë¶ˆìš©ì–´ê°€ íƒœê·¸ë¡œ ë‚˜íƒ€ë‚˜ëŠ” ë¬¸ì œ í•´ê²°
- **ìƒí’ˆ ë¦¬ë·° ë¶„ì„**: ë¦¬ë·°ì—ì„œ ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•˜ì—¬ ìƒí’ˆ íŠ¹ì„± íŒŒì•…
- **ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ë¥˜**: ê¸°ì‚¬ ë‚´ìš©ì—ì„œ í•µì‹¬ í† í”½ë§Œ ì¶”ì¶œí•˜ì—¬ ìë™ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜

## ğŸ“ ê´€ë ¨ ë¬¸ì œ

**Question:** A data scientist is developing a model that selects tags from blog articles using the Amazon SageMaker Neural Topic Model (NTM) algorithm. The raw blog post data is kept in JSON format in an Amazon S3 bucket. During model assessment, the data scientist observed that the model proposes certain stopwords such as "a," "an," and "the" as tags for certain blog postings, as well as a few uncommon words that appear in just particular blog entries. Following many cycles of tag review with the content team, the data scientist observes that the rare terms are uncommon yet viable. Additionally, the data scientist must check that the resulting model's tag suggestions do not include stopwords. What actions should the data scientist take to ensure compliance with these requirements?

**Options:**

- A) Use the Amazon Comprehend entity recognition API operations. Remove the detected words from the blog post data. Replace the blog post data source in the S3 bucket.
- B) Run the SageMaker built-in principal component analysis (PCA) algorithm with the blog post data from the S3 bucket as the data source. Replace the blog post data in the S3 bucket with the results of the training job.
- C) Use the SageMaker built-in Object Detection algorithm instead of the NTM algorithm for the training job to process the blog post data.
- D) Remove the stopwords from the blog post data by using the CountVectorizer function in the scikit-learn library. Replace the blog post data in the S3 bucket with the results of the vectorizer.

**ì •ë‹µ: D) CountVectorizerë¥¼ í†µí•œ ë¶ˆìš©ì–´ ì œê±°**

ğŸ’¡ ì¶”ê°€ ì„¤ëª…:

- **ì„ íƒì§€ A** - Amazon ComprehendëŠ” ê°œì²´ ì¸ì‹(Named Entity Recognition)ì— íŠ¹í™”ë˜ì–´ ìˆì–´ ë¶ˆìš©ì–´ ì œê±°ì™€ëŠ” ì§ì ‘ì  ê´€ë ¨ì´ ì—†ìŒ
- **ì„ íƒì§€ B** - PCAëŠ” ì°¨ì› ì¶•ì†Œ ê¸°ë²•ìœ¼ë¡œ í† í”½ ëª¨ë¸ë§ì´ë‚˜ ë¶ˆìš©ì–´ ì œê±° ëª©ì ê³¼ ë¬´ê´€í•¨
- **ì„ íƒì§€ C** - Object Detectionì€ ì´ë¯¸ì§€ ì²˜ë¦¬ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ í…ìŠ¤íŠ¸ ê¸°ë°˜ í† í”½ ëª¨ë¸ë§ê³¼ ì™„ì „íˆ ë‹¤ë¥¸ ì˜ì—­ì„
- **í•µì‹¬ ì´í•´**: CountVectorizerëŠ” ë²¡í„°í™” ê³¼ì •ì—ì„œ stop_words ë§¤ê°œë³€ìˆ˜ë¥¼ í†µí•´ ë¶ˆìš©ì–´ë¥¼ í•™ìŠµ ë°ì´í„°ì—ì„œ ì›ì²œ ë°°ì œí•˜ë¯€ë¡œ, NTMì´ ë¶ˆìš©ì–´ë¥¼ í•™ìŠµí•  ê¸°íšŒ ìì²´ë¥¼ ì°¨ë‹¨í•¨