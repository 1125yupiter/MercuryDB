# K-최근접 이웃 알고리즘 완전 가이드
## K-NN Algorithm Comprehensive Guide

---

## 목차
1. [K-NN 기본 개념](#knn-기본-개념)
2. [K-NN 작동 원리](#knn-작동-원리)
3. [거리 측정 방법](#거리-측정-방법)
4. [핵심 매개변수](#핵심-매개변수)
5. [실생활 비유로 이해하기](#실생활-비유로-이해하기)
6. [결론](#결론)

---

## K-NN 기본 개념

### 정의
**K-최근접 이웃(K-Nearest Neighbors, K-NN)** 알고리즘은 분류와 회귀 작업 모두에 사용되는 지도 학습 알고리즘입니다.

### 핵심 특징
- **지도 학습**: 라벨이 있는 훈련 데이터셋이 필요
- **비모수적 알고리즘**: 데이터 분포에 대한 가정 없음
- **게으른 학습**: 훈련 시점이 아닌 예측 시점에 계산 수행
- **인스턴스 기반**: 저장된 인스턴스와의 유사성을 기반으로 예측

### 핵심 원리
"유유상종" - 비슷한 데이터 포인트는 비슷한 라벨을 가진다는 가정하에 작동합니다.

---

## K-NN 작동 원리

### 알고리즘 단계
1. **저장**: 모든 훈련 데이터 포인트 저장
2. **거리 계산**: 질의 포인트와 모든 훈련 포인트 간의 거리 계산
3. **정렬**: 거리를 오름차순으로 정렬
4. **선택**: K개의 최근접 이웃 선택
5. **예측**: 최종 예측값 결정
   - **분류**: 다수결 투표
   - **회귀**: 평균값 계산

### 예측 시점 실행
K-NN은 "게으른" 알고리즘으로, 훈련 시에는 아무 작업도 하지 않고 예측이 필요할 때만 위의 단계들을 실행합니다.

---

## 거리 측정 방법

### 1. 유클리드 거리 (Euclidean Distance)
- **공식**: d = √[(x₁-y₁)² + (x₂-y₂)² + ... + (xₙ-yₙ)²]
- **비유**: 슈퍼맨의 비행 - 직선 거리
- **특징**: 가장 일반적으로 사용, 스케일에 민감

### 2. 맨해튼 거리 (Manhattan Distance)
- **공식**: d = |x₁-y₁| + |x₂-y₂| + ... + |xₙ-yₙ|
- **비유**: 도시 블록을 걷는 거리
- **특징**: 고차원 데이터에 적합

### 3. 민코우스키 거리 (Minkowski Distance)
- **공식**: d = (Σ|xᵢ-yᵢ|ᵖ)^(1/p)
- **비유**: 변신술사 - p값에 따라 변화
- **특징**: p=1일 때 맨해튼, p=2일 때 유클리드

### 4. 해밍 거리 (Hamming Distance)
- **공식**: 서로 다른 위치의 개수
- **비유**: 이산적 카운터
- **특징**: 범주형 변수에 사용

### 5. 코사인 유사도 (Cosine Similarity)
- **공식**: cos(θ) = (A·B)/(||A||×||B||)
- **비유**: 나침반 - 방향 측정
- **특징**: 텍스트 데이터에 적합

---

## 핵심 매개변수

### K값 선택

#### 작은 K값 (K=1, K=3)
- **장점**: 패턴을 세밀하게 감지
- **단점**: 
  - 노이즈에 민감
  - 낮은 편향, 높은 분산
  - 과적합 위험
- **비유**: **십대** - 경험이 적어 작은 변화에도 크게 반응

#### 큰 K값 (K=20, K=50)
- **장점**: 안정적인 결정 경계
- **단점**:
  - 높은 편향, 낮은 분산
  - 과소적합 위험
- **비유**: **어른** - 경험이 많아 안정적이지만 새로운 패턴을 놓칠 수 있음

#### K값 결정 방법
- **경험 법칙**: K = √n (n은 훈련 샘플 수)
- **교차 검증**을 통한 최적 K값 찾기
- **이진 분류**: 홀수 K 사용 (동점 방지)

### 가중치 함수
- **균등 가중치**: 모든 이웃이 동등하게 기여
- **거리 가중치**: 가까운 이웃이 더 큰 영향력
  - 가중치 = 1/거리
  - K가 클 때 유용

---

## 실생활 비유로 이해하기

### 거리 측정 비유
- **유클리드**: 슈퍼맨 (직선 비행)
- **맨해튼**: 보행자 (격자 이동)
- **민코우스키**: 변신술사 (상황에 따라 변화)
- **해밍**: 이산 카운터 (차이점 세기)
- **코사인**: 나침반 (방향 측정)

### K값과 인생 경험 비유
- **작은 K (십대)**: 
  - 적은 경험으로 급작스러운 결정
  - 하루 안 좋은 일로 인생 전체를 바꾸려 함
  - 높은 분산 (기분 변화 심함)
  - 낮은 편향 (열린 마음)

- **큰 K (어른)**: 
  - 많은 경험으로 신중한 판단
  - 안정적이지만 새로운 시작이 어려움
  - 낮은 분산 (일관된 행동)
  - 높은 편향 (고정된 사고)

---

## 결론

K-NN 알고리즘은 직관적이고 이해하기 쉬운 머신러닝 알고리즘입니다. "유유상종"의 원리를 바탕으로 하며, 적절한 K값과 거리 측정 방법을 선택하는 것이 핵심입니다.

**핵심 포인트**:
- 지도 학습이지만 게으른 학습 방식
- 예측 시점에만 계산 수행
- K값과 거리 측정 방법이 성능에 큰 영향
- 십대와 어른의 비유로 K값의 특성 이해
- 교차 검증을 통한 최적 매개변수 선택 필요

---

### 해시태그
#KNN알고리즘 #최근접이웃 #머신러닝 #지도학습 #데이터사이언스 #인공지능 #패턴인식 #분류알고리즘 #회귀분석 #빅데이터